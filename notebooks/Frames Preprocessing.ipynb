{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "frames = json.load(open('../data/frames/frames.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Slots dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'airport', 'university', 'cathedral', 'mall', 'amenities', 'budget', 'gym', 'downtown', 'arr_time_dst', 'seat_ok', 'duration', 'museum', 'flex', 'n_adults', 'wifi', 'market', 'n_children', 'seat', 'park', 'shopping', 'end_date_ok', 'str_date_ok', 'min_duration', 'dst_city', 'palace', 'gst_rating', 'price', 'count_name', 'arr_time_or', 'or_city', 'str_date', 'budget_ok', 'breakfast', 'count_dst_city', 'theatre', 'name', 'max_duration', 'spa', 'end_date', 'vicinity', 'count_amenities', 'impl_anaphora', 'category', 'parking', 'beach', 'count', 'dst_city_ok', 'dep_time_dst', 'count_category', 'dep_time_or'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'<NO_SLOT>': 0,\n",
       " 'budget': 1,\n",
       " 'dst_city': 2,\n",
       " 'duration': 3,\n",
       " 'end_date': 4,\n",
       " 'gst_rating': 5,\n",
       " 'n_adults': 6,\n",
       " 'n_children': 7,\n",
       " 'or_city': 8,\n",
       " 'price': 9,\n",
       " 'seat': 10,\n",
       " 'str_date': 11}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slots = set()\n",
    "\n",
    "for dialog in frames:\n",
    "    for turn in dialog['turns']:\n",
    "        acts = list(filter(lambda act: act.get('name') in {'inform', 'suggest', 'request', 'offer'}, turn.get('labels').get('acts', [])))\n",
    "        for act in acts:\n",
    "            for arg in act.get('args', []):\n",
    "                if arg.get('key') in {'action', 'ref', 'ref_anaphora', 'read', 'write', 'id', 'intent'}:\n",
    "                    continue\n",
    "                else:\n",
    "                    slots.add(arg.get('key'))\n",
    "                    \n",
    "print(slots)\n",
    "\n",
    "slots = {'or_city', 'dst_city', 'str_date', 'end_date', 'duration', 'budget', 'price', 'n_adults', 'n_children', 'seat', 'gst_rating'}\n",
    "\n",
    "slots_dictionary = {\n",
    "    '<NO_SLOT>': 0,\n",
    "}\n",
    "\n",
    "for slot_type_idx, slot_type in enumerate(sorted(slots)):\n",
    "    slots_dictionary[slot_type] = slot_type_idx + 1\n",
    "\n",
    "with open('../data/processed/frames/v5/slots_dictionary.json', 'w') as f:\n",
    "    json.dump(slots_dictionary, f)\n",
    "    \n",
    "slots_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Actions dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<PAD>': 0, 'book': 4, 'end': 3, 'query': 2, 'speak': 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions_dictionary = {\n",
    "    '<PAD>': 0,\n",
    "    'speak': 1,\n",
    "    'query': 2,\n",
    "    'end': 3,\n",
    "    'book': 4\n",
    "}\n",
    "    \n",
    "with open('../data/processed/frames/v5/actions_dictionary.json', 'w') as f:\n",
    "    json.dump(actions_dictionary, f)\n",
    "    \n",
    "actions_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def parse_slots(acts):\n",
    "    parsed = {}\n",
    "    for act in acts:\n",
    "        if act['name'] in {'inform'}:\n",
    "            for arg in act['args']:\n",
    "                if arg['key'] in slots_dictionary:\n",
    "                    parsed[arg['key']] = str(arg['val'])\n",
    "    return parsed\n",
    "\n",
    "def parse_agent_slots(turn):\n",
    "    if turn is None:\n",
    "        return {}, set()\n",
    "    \n",
    "    informed, requested = {}, set()\n",
    "    for act in turn['labels']['acts']:\n",
    "        if act['name'] in {'inform', 'offer', 'suggest'}:\n",
    "            for arg in act['args']:\n",
    "                if arg['key'] in slots_dictionary and arg.get('val') is not None:\n",
    "                    informed[arg['key']] = str(arg['val'])\n",
    "        if act['name'] in {'request'}:\n",
    "            for arg in act['args']:\n",
    "                requested.add(arg['key'])\n",
    "            \n",
    "    return informed, requested\n",
    "\n",
    "def parse_user_intents(turn):\n",
    "    if turn is None:\n",
    "        return set()\n",
    "    \n",
    "    result = set()\n",
    "    for act in turn['labels']['acts']:\n",
    "        result.add(act['name'])\n",
    "        for arg in act['args']:\n",
    "            if arg['key'] == 'intent':\n",
    "                result.add(arg['val'])\n",
    "    return result\n",
    "\n",
    "def parse_agent_actions(turn):\n",
    "    if turn is None:\n",
    "        return set()\n",
    "\n",
    "    result = set()\n",
    "    for act in turn['labels']['acts']:\n",
    "        result.add(act['name'])\n",
    "        for arg in act['args']:\n",
    "            if arg['key'] == 'action':\n",
    "                result.add(arg['val'])\n",
    "    return result \n",
    "\n",
    "def parse_agent_action(previous_turn, turn, next_turn, next_user_turn):\n",
    "    previous_turn_actions = parse_agent_actions(previous_turn)\n",
    "    user_intents = parse_user_intents(turn)\n",
    "    next_user_intents = parse_user_intents(next_user_turn)\n",
    "    next_turn_actions = parse_agent_actions(next_turn)\n",
    "    \n",
    "    if 'book' in previous_turn_actions and 'affirm' in user_intents:\n",
    "        return 'book'\n",
    "    \n",
    "    if 'book' in next_turn_actions and 'thankyou' in next_user_intents and 'affirm' not in next_user_intents:\n",
    "        return 'book'\n",
    "    \n",
    "    if next_turn is None or len(next_turn['text']) == 0:\n",
    "        if 'book' in user_intents:\n",
    "            return 'book'\n",
    "        return 'end'\n",
    "    \n",
    "    if 'goodbye' in next_turn_actions and next_user_turn is None:\n",
    "        return 'end'\n",
    "    \n",
    "    return 'speak'\n",
    "\n",
    "def parse_offer_frame_id(next_turn):\n",
    "    if next_turn is None:\n",
    "        return None\n",
    "\n",
    "    for act in next_turn['labels']['acts']:\n",
    "        if act['name'] == 'offer':\n",
    "            for arg in act['args']:\n",
    "                if arg['key'] == 'id':\n",
    "                    return arg['val']\n",
    "                \n",
    "def parse_turn_frames(frames):\n",
    "    for frame in frames:\n",
    "        yield frame['frame_id'], parse_frame(frame)\n",
    "\n",
    "def parse_frame(frame):\n",
    "    parsed = {}\n",
    "    for key, val in frame.get('info', {}).items():\n",
    "        val = val[0].get('val')\n",
    "        if val is not None:\n",
    "            parsed[key] = str(val)\n",
    "    return parsed\n",
    "\n",
    "def parse_query_state(next_turn, offer_frame_id):\n",
    "    if next_turn is None:\n",
    "        return 'no_query'\n",
    "    \n",
    "    next_turn_actions = set([a['name'] for a in next_turn['labels']['acts']])\n",
    "    \n",
    "    if len(next_turn['db']['search']) > 0:\n",
    "        if 'no_result' in next_turn_actions:\n",
    "            return 'no_result'\n",
    "        \n",
    "        if len({'offer', 'suggest', 'inform'}.intersection(next_turn_actions)) > 0:\n",
    "            if len(next_turn['db']['result']) > 0:\n",
    "                return 'result'\n",
    "            return 'no_result'\n",
    "            \n",
    "    return 'no_query'\n",
    "\n",
    "def parse_query_result(frames, frame_id):\n",
    "    if frame_id is None:\n",
    "        return {}\n",
    "    \n",
    "    result = {}\n",
    "    for key, val in frames[frame_id].items():\n",
    "        if key in slots_dictionary:\n",
    "            result[key] = val\n",
    "    return result\n",
    "        \n",
    "def replace_delexicalized(text, arg):\n",
    "    if arg['key'] in slots_dictionary and arg.get('val') is not None:\n",
    "        text = text.replace(arg['val'], '.SLOT.%s' % arg['key'])\n",
    "    return text\n",
    "        \n",
    "        \n",
    "def delexicalize(turn):\n",
    "    if turn is None:\n",
    "        return ''\n",
    "    \n",
    "    text = str(turn['text'])\n",
    "    for act in turn['labels']['acts']:\n",
    "        if act['name'] in {'request'}:\n",
    "            continue\n",
    "        for arg in act.get('args', []):\n",
    "            text = replace_delexicalized(text, arg)\n",
    "            if arg['key'] == 'ref':\n",
    "                for val in arg.get('val', []):\n",
    "                    for annotation in val.get('annotations', []):\n",
    "                        text = replace_delexicalized(text, annotation)\n",
    "    return text\n",
    "\n",
    "def process_turn(turn_idx, n_turns, turn, previous_turn, next_turn, next_user_turn, frames):\n",
    "    offer_frame_id = parse_offer_frame_id(next_turn)\n",
    "    query_result_state = parse_query_state(next_turn, offer_frame_id)\n",
    "    \n",
    "    base = {\n",
    "        'text': str(turn['text']),\n",
    "        'slots': parse_slots(turn['labels']['acts_without_refs']),\n",
    "        'previous_response': str(previous_turn['text'] if previous_turn is not None else ''),\n",
    "        'previous_response_delexicalized': delexicalize(previous_turn),\n",
    "        'next_response': str(next_turn['text'] if next_turn is not None else ''),\n",
    "        'next_response_delexicalized': delexicalize(next_turn),\n",
    "        'query_state': 'no_query',\n",
    "        'query_result': {},\n",
    "        'next_action': 'speak'\n",
    "    }\n",
    "    \n",
    "    if query_result_state in {'result', 'no_result'}:\n",
    "        yield dict(base, next_action='query')\n",
    "    \n",
    "    yield dict(\n",
    "        base,\n",
    "        query_state=query_result_state,\n",
    "        query_result=parse_query_result(frames, offer_frame_id),\n",
    "        next_action=parse_agent_action(previous_turn, turn, next_turn, next_user_turn)\n",
    "    )\n",
    "\n",
    "processed_frames = []\n",
    "for dialog in frames:\n",
    "    parsed_frames = {}\n",
    "    for turn in dialog['turns']:\n",
    "        for frame_id, parsed in parse_turn_frames(turn['labels']['frames']):\n",
    "            if frame_id in parsed_frames:\n",
    "                parsed_frames[frame_id] = dict(parsed_frames[frame_id], **parsed)\n",
    "            else:\n",
    "                parsed_frames[frame_id] = parsed\n",
    "    \n",
    "    processed_turns, n_book_actions = [], 0\n",
    "    for i, turn in enumerate(dialog['turns']):\n",
    "        previous_processed_turn = processed_turns[-1] if len(processed_turns) > 0 else None\n",
    "        previous_turn = dialog['turns'][i-1] if i > 0 else None\n",
    "        next_turn = dialog['turns'][i+1] if i < len(dialog['turns'])-1 else None\n",
    "        next_user_turn = dialog['turns'][i+2] if i < len(dialog['turns'])-2 else None\n",
    "        \n",
    "        if turn['author'] == 'user':            \n",
    "            for processed_turn in process_turn(i, len(dialog['turns']), turn, previous_turn, next_turn, next_user_turn, parsed_frames):\n",
    "                processed_turns.append(processed_turn)\n",
    "                if processed_turn['next_action'] == 'book':\n",
    "                    n_book_actions += 1\n",
    "    \n",
    "    for i, processed_turn in enumerate(processed_turns):\n",
    "        processed_turns[i] = dict(processed_turn, was_booked=int(n_book_actions > 0))\n",
    "\n",
    "    processed_frames.append(processed_turns)\n",
    "    \n",
    "with open('../data/processed/frames/v5/processed_frames.json', 'w') as f:\n",
    "    json.dump(processed_frames, f)\n",
    "    \n",
    "len(processed_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'hello, please find me a vacation between saturday august 27 2016 and wednesday september 7 2016 for under 6000$ leaving from madrid', 'slots': {'str_date': 'saturday august 27 2016', 'end_date': 'wednesday september 7 2016', 'budget': '6000$', 'or_city': 'madrid'}, 'previous_response': '', 'previous_response_delexicalized': '', 'next_response': 'Hello, what can I help you with today?', 'next_response_delexicalized': 'Hello, what can I help you with today?', 'query_state': 'no_query', 'query_result': {}, 'next_action': 'speak', 'was_booked': 1}\n",
      "\n",
      "{'text': 'hello, please find me a vacation between saturday august 27 2016 and wednesday sept 7 for under 6000$ leaving from madrid', 'slots': {'str_date': 'saturday august 27', 'end_date': 'wednesday sept 7', 'budget': '6000$', 'or_city': 'madrid'}, 'previous_response': 'Hello, what can I help you with today?', 'previous_response_delexicalized': 'Hello, what can I help you with today?', 'next_response': 'Ok! Absolutely :slightly_smiling_face: I can book you a trip to Rome from September 2-7 for only $407.55 if you are interested.', 'next_response_delexicalized': 'Ok! Absolutely :slightly_smiling_face: I can book you a trip to .SLOT.dst_city from .SLOT.str_date-.SLOT.end_date for only $40.SLOT.end_date.55 if you are interested.', 'query_state': 'no_query', 'query_result': {}, 'next_action': 'query', 'was_booked': 1}\n",
      "\n",
      "{'text': 'hello, please find me a vacation between saturday august 27 2016 and wednesday sept 7 for under 6000$ leaving from madrid', 'slots': {'str_date': 'saturday august 27', 'end_date': 'wednesday sept 7', 'budget': '6000$', 'or_city': 'madrid'}, 'previous_response': 'Hello, what can I help you with today?', 'previous_response_delexicalized': 'Hello, what can I help you with today?', 'next_response': 'Ok! Absolutely :slightly_smiling_face: I can book you a trip to Rome from September 2-7 for only $407.55 if you are interested.', 'next_response_delexicalized': 'Ok! Absolutely :slightly_smiling_face: I can book you a trip to .SLOT.dst_city from .SLOT.str_date-.SLOT.end_date for only $40.SLOT.end_date.55 if you are interested.', 'query_state': 'result', 'query_result': {'budget': '6000.0', 'dst_city': 'Rome', 'or_city': 'madrid', 'end_date': 'sept 7', 'str_date': 'september 2', 'price': '407.55'}, 'next_action': 'speak', 'was_booked': 1}\n",
      "\n",
      "{'text': 'ok. can it be for a longer period', 'slots': {}, 'previous_response': 'Ok! Absolutely :slightly_smiling_face: I can book you a trip to Rome from September 2-7 for only $407.55 if you are interested.', 'previous_response_delexicalized': 'Ok! Absolutely :slightly_smiling_face: I can book you a trip to .SLOT.dst_city from .SLOT.str_date-.SLOT.end_date for only $40.SLOT.end_date.55 if you are interested.', 'next_response': 'What about Essen for 610.86USD? You would leave August 30th and return on September 7th.', 'next_response_delexicalized': 'What about .SLOT.dst_city for .SLOT.price? You would leave .SLOT.str_date and return on .SLOT.end_date.', 'query_state': 'no_query', 'query_result': {'budget': '6000.0', 'dst_city': 'Essen', 'str_date': 'august 30', 'end_date': 'september 7', 'or_city': 'madrid', 'price': '610.86'}, 'next_action': 'speak', 'was_booked': 1}\n",
      "\n",
      "{'text': 'ok', 'slots': {}, 'previous_response': 'What about Essen for 610.86USD? You would leave August 30th and return on September 7th.', 'previous_response_delexicalized': 'What about .SLOT.dst_city for .SLOT.price? You would leave .SLOT.str_date and return on .SLOT.end_date.', 'next_response': 'Shall I go ahead and book that for you?', 'next_response_delexicalized': 'Shall I go ahead and book that for you?', 'query_state': 'no_query', 'query_result': {}, 'next_action': 'speak', 'was_booked': 1}\n",
      "\n",
      "{'text': 'ok', 'slots': {}, 'previous_response': 'Shall I go ahead and book that for you?', 'previous_response_delexicalized': 'Shall I go ahead and book that for you?', 'next_response': 'Wonderful, all booked :slightly_smiling_face: Enjoy your stay.', 'next_response_delexicalized': 'Wonderful, all booked :slightly_smiling_face: Enjoy your stay.', 'query_state': 'no_query', 'query_result': {}, 'next_action': 'book', 'was_booked': 1}\n",
      "\n",
      "{'text': 'thanks', 'slots': {}, 'previous_response': 'Wonderful, all booked :slightly_smiling_face: Enjoy your stay.', 'previous_response_delexicalized': 'Wonderful, all booked :slightly_smiling_face: Enjoy your stay.', 'next_response': '', 'next_response_delexicalized': '', 'query_state': 'no_query', 'query_result': {}, 'next_action': 'end', 'was_booked': 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for turn in processed_frames[300]:\n",
    "    print(turn)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Word dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def normalize_token(token, replace_digits=True):\n",
    "    m = re.match('(\\d+(?:\\.?\\d+)?)', token)\n",
    "    if m is not None:\n",
    "        prefix = token[:m.start()]\n",
    "        if len(prefix) > 0:\n",
    "            yield prefix\n",
    "        \n",
    "        if replace_digits:\n",
    "            yield '.DIGIT'\n",
    "        else:\n",
    "            yield m.group(1)\n",
    "            \n",
    "        suffix = token[(m.start()+len(m.group(1))):]\n",
    "        if len(suffix) > 0:\n",
    "            yield suffix\n",
    "    elif token[:5] == '.slot':\n",
    "        yield str(token[:5].upper()) + token[5:]\n",
    "    else:\n",
    "        yield token\n",
    "\n",
    "def tokenize(text, replace_digits=True):\n",
    "    tokens = nltk.word_tokenize(str(text).lower())\n",
    "    return [normalized_token for token in tokens for normalized_token in normalize_token(token, replace_digits)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'can', 'book', 'you', 'a', '.SLOT.seat', 'for', '123', '$', 'more', '.']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize('I can book you a .SLOT.seat for 123$ more.', replace_digits=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "def word_iterator(processed_frames):\n",
    "    for frame in processed_frames:\n",
    "        for turn in frame:\n",
    "            for token in tokenize(turn['text']):\n",
    "                yield token\n",
    "            for token in tokenize(turn['next_response']):\n",
    "                yield token\n",
    "                \n",
    "word_counts = collections.Counter(word_iterator(processed_frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4381"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dictionary = {\n",
    "    '<PAD>': 0,\n",
    "    '<EOS>': 1,\n",
    "    '<UNK>': 2,\n",
    "    '.DIGIT': 3,\n",
    "}\n",
    "\n",
    "for slot in sorted(slots):\n",
    "    word_dictionary['.SLOT.{0}'.format(slot)] = len(word_dictionary)\n",
    "    \n",
    "embeddings = np.random.randn(len(word_dictionary), 300)\n",
    "embeddings[0, :] = 0.0\n",
    "embeddings[1, :] = 1.0\n",
    "embeddings = embeddings.tolist()\n",
    "\n",
    "assert len(embeddings) == len(word_dictionary)\n",
    "\n",
    "\n",
    "with open('../data/glove/glove.42B.300d.txt') as f:\n",
    "    for line in f:\n",
    "        line = line.split(' ')\n",
    "        word = str(line[0]).lower()\n",
    "        vec = np.array(line[1:]).astype(float).tolist()\n",
    "            \n",
    "        if word in word_counts:\n",
    "            word_dictionary[word] = len(word_dictionary)\n",
    "            embeddings.append(vec)\n",
    "            \n",
    "assert len(embeddings) == len(word_dictionary)\n",
    "\n",
    "with open('../data/processed/frames/v5/word_dictionary.json', 'w') as f:\n",
    "    json.dump(word_dictionary, f)\n",
    "    \n",
    "with open('../data/processed/frames/v5/embeddings.json', 'w') as f:\n",
    "    json.dump(embeddings, f)\n",
    "    \n",
    "len(word_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4381"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dictionary = json.load(open('../data/processed/frames/v5/word_dictionary.json', 'r'))\n",
    "len(word_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'book': 0.04896561988391129,\n",
       " 'end': 0.06154189611549338,\n",
       " 'query': 0.22555439797588928,\n",
       " 'speak': 0.663938086024706}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def actions_iterator(processed_frames):\n",
    "    for frame in processed_frames:\n",
    "        for turn in frame:\n",
    "            yield turn['next_action']\n",
    "\n",
    "actions_count = collections.Counter(actions_iterator(processed_frames))\n",
    "total_actions_count = sum([count for _, count in actions_count.most_common()])\n",
    "\n",
    "action_frequencies = {}\n",
    "for action, count in actions_count.most_common():\n",
    "    action_frequencies[action] = count*1.0 / total_actions_count\n",
    "    \n",
    "with open('../data/processed/frames/v5/action_frequencies.json', 'w') as f:\n",
    "    json.dump(action_frequencies, f)\n",
    "action_frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "embedded_frames = []\n",
    "\n",
    "QUERY_STATES = {\n",
    "    'no_query': 0,\n",
    "    'no_result': 1,\n",
    "    'result': 2\n",
    "}\n",
    "\n",
    "def embed_text(text):\n",
    "    return [word_dictionary.get(token, 2) for token in tokenize(text)]\n",
    "\n",
    "def embed_complex(struct):\n",
    "    embedded = {}\n",
    "    for key in struct.keys():\n",
    "        embedded[slots_dictionary[key]] = embed_text(struct[key])\n",
    "        \n",
    "    assert len(struct) == len(embedded)\n",
    "    return embedded\n",
    "\n",
    "def token_slot_ids(turn):\n",
    "    tokens = tokenize(turn['text'], replace_digits=False)\n",
    "    positions_with_slot = set()\n",
    "\n",
    "    for slot, value in turn['slots'].items():\n",
    "        value_embedded = tokenize(value, replace_digits=False)\n",
    "        for i in range(len(tokens)-len(value_embedded)):\n",
    "            if tokens[i:i+len(value_embedded)] == value_embedded:\n",
    "                for j in range(i, i+len(value_embedded)):\n",
    "                    positions_with_slot.add(j)\n",
    "                    tokens[j] = slots_dictionary[slot]\n",
    "                    \n",
    "    for i in range(len(tokens)):\n",
    "        if i not in positions_with_slot:\n",
    "            tokens[i] = 0\n",
    "            \n",
    "    return tokens\n",
    "\n",
    "def slot_any(turn):\n",
    "    states = []\n",
    "    for slot, slot_value in turn['slots'].items():\n",
    "        if slot_value == '-1':\n",
    "            states.append(slots_dictionary[slot])\n",
    "    return states\n",
    "\n",
    "def embed_turn(turn):\n",
    "    token_ids = embed_text(turn['text'])\n",
    "    token_slots = token_slot_ids(turn)\n",
    "    \n",
    "    assert len(token_ids) == len(token_slots)\n",
    "\n",
    "    return {\n",
    "        'token_ids': token_ids,\n",
    "        'token_slot_ids': token_slots,\n",
    "        'slot_any': slot_any(turn),\n",
    "        'previous_response_token_ids': embed_text(turn['previous_response']),\n",
    "        'next_response_token_ids': embed_text(turn['next_response']),\n",
    "        'previous_response_delexicalized_token_ids': embed_text(turn['previous_response_delexicalized']),\n",
    "        'next_response_delexicalized_token_ids': embed_text(turn['next_response_delexicalized']),\n",
    "        'next_action': actions_dictionary[turn['next_action']],\n",
    "        'query_state': QUERY_STATES[turn['query_state']],\n",
    "        'query_result': embed_complex(turn['query_result']),\n",
    "        'was_booked': turn['was_booked']\n",
    "    }\n",
    "\n",
    "embedded_frames = []\n",
    "for frame in processed_frames:\n",
    "    embedded_turns = []\n",
    "    for turn in frame:\n",
    "        embedded_turns.append(embed_turn(turn))\n",
    "    embedded_frames.append(embedded_turns)\n",
    "        \n",
    "assert len(embedded_frames) == len(processed_frames)\n",
    "\n",
    "with open('../data/processed/frames/v5/embedded_frames.json', 'w') as f:\n",
    "    json.dump(embedded_frames, f)\n",
    "    \n",
    "random.shuffle(embedded_frames)\n",
    "\n",
    "with open('../data/processed/frames/v5/embedded_frames_train.json', 'w') as f:\n",
    "    json.dump(embedded_frames[:1200], f)\n",
    "\n",
    "with open('../data/processed/frames/v5/embedded_frames_test.json', 'w') as f:\n",
    "    json.dump(embedded_frames[1200:], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[1]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[1]\n",
      "[4]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[11, 4]\n",
      "[11, 4]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[2]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[2, 11, 4]\n",
      "[2, 11, 4]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for frame in embedded_frames[:10]:\n",
    "    for turn in frame:\n",
    "        print(turn['slot_any'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 943,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('../data/processed/frames/v3/database.json', 'w') as f:\n",
    "    json.dump(list(database.values()), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 991,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "value_slots, boolean_slots = set(), set()\n",
    "user_slots = set()\n",
    "\n",
    "for dialog in frames:\n",
    "    for turn in dialog['turns']:\n",
    "        acts = list(filter(lambda act: act.get('name') in {'inform', 'suggest', 'request', 'offer'}, turn.get('labels').get('acts', [])))\n",
    "        for act in acts:\n",
    "            for arg in act.get('args', []):\n",
    "                if arg.get('key') in {'action', 'ref', 'ref_anaphora', 'read', 'write', 'id', 'intent'}:\n",
    "                    continue\n",
    "                if turn['author'] == 'user':\n",
    "                    user_slots.add(arg.get('key'))\n",
    "                if isinstance(arg.get('val'), bool):\n",
    "                    boolean_slots.add(arg.get('key'))\n",
    "                else:\n",
    "                    value_slots.add(arg.get('key'))\n",
    "\n",
    "value_slots = value_slots.difference(boolean_slots)\n",
    "\n",
    "slots_dictionary = {\n",
    "    '<NO_SLOT>': 0,\n",
    "}\n",
    "\n",
    "for slot_type_idx, slot_type in enumerate(value_slots.union(boolean_slots)):\n",
    "    slots_dictionary[slot_type] = slot_type_idx + 1\n",
    "\n",
    "with open('../data/processed/frames/v3/slots_dictionary.json', 'w') as f:\n",
    "    json.dump(slots_dictionary, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 992,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "agent_actions = set()\n",
    "agent_sub_actions = set()\n",
    "\n",
    "for dialog in frames:\n",
    "    for turn in dialog['turns']:\n",
    "        if turn['author'] == 'wizard':\n",
    "            for act in turn['labels']['acts']:\n",
    "                agent_actions.add(act['name'])\n",
    "                if act['name'] in {'inform', 'request', 'suggest', 'offer'}:\n",
    "                     for arg in act['args']:\n",
    "                        if arg['key'] in slots_dictionary:\n",
    "                            agent_sub_actions.add('{0}.{1}'.format(act['name'], arg['key']))\n",
    "\n",
    "agent_actions_dictionary = {\n",
    "    '<NO_ACTION>': 0,\n",
    "}\n",
    "agent_sub_actions_dictionary = {\n",
    "    '<NO_ACTION>': 0,\n",
    "}\n",
    "    \n",
    "for action_idx, action in enumerate(sorted(agent_actions)):\n",
    "    agent_actions_dictionary[action] = action_idx + 1\n",
    "\n",
    "for action_idx, action in enumerate(sorted(agent_sub_actions)):\n",
    "    agent_sub_actions_dictionary[action] = action_idx + 1\n",
    "    \n",
    "with open('../data/processed/frames/v3/agent_actions_dictionary.json', 'w') as f:\n",
    "    json.dump(agent_actions_dictionary, f)\n",
    "\n",
    "with open('../data/processed/frames/v3/agent_sub_actions_dictionary.json', 'w') as f:\n",
    "    json.dump(agent_sub_actions_dictionary, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "used_words = set()\n",
    "\n",
    "for dialog in frames:\n",
    "    for turn in dialog['turns']:\n",
    "        used_words.update(nltk.word_tokenize(str(turn['text']).lower()))\n",
    "used_words.update(set(string.ascii_lowercase))\n",
    "used_words.update(set(string.digits))\n",
    "\n",
    "embeddings = [\n",
    "    np.zeros(300).tolist(),\n",
    "    np.ones(300).tolist(),\n",
    "    np.random.normal(scale=.3, size=300).tolist(),\n",
    "    np.random.normal(scale=.3, size=300).tolist(),\n",
    "    np.random.normal(scale=.3, size=300).tolist(),\n",
    "    np.random.normal(scale=.3, size=300).tolist(),\n",
    "]\n",
    "embeddings.extend(np.random.normal(scale=.3, size=(len(slots_dictionary), 300)).tolist())\n",
    "\n",
    "glove_dictionary = {\n",
    "    '<PAD>': 0,\n",
    "    '<EOS>': 1,\n",
    "    '<UNK>': 2,\n",
    "    '<VAL.true>': 3,\n",
    "    '<VAL.false>': 4,\n",
    "    '<VAL.any>': 5,\n",
    "}\n",
    "glove_dictionary_offset = len(glove_dictionary)\n",
    "\n",
    "for (key, idx) in sorted(slots_dictionary.items(), key=lambda x: x[1]):\n",
    "    glove_dictionary['<SLOT.{0}>'.format(key)] = idx + glove_dictionary_offset\n",
    "\n",
    "glove_dictionary_offset = len(glove_dictionary)\n",
    "assert len(glove_dictionary) == len(embeddings)\n",
    "\n",
    "with open('../data/glove/glove.42B.300d.txt') as f:\n",
    "    i = 0\n",
    "    for line in f:\n",
    "        line = line.split(' ')\n",
    "        word = str(line[0]).lower()\n",
    "        vec = np.array(line[1:]).astype(float).tolist()\n",
    "            \n",
    "        if word in used_words:\n",
    "            glove_dictionary[word] = glove_dictionary_offset + i\n",
    "            embeddings.append(vec)\n",
    "            i += 1\n",
    "            \n",
    "assert len(glove_dictionary) == len(embeddings)\n",
    "\n",
    "with open('../data/processed/frames/v3/glove_dictionary.json', 'w') as f:\n",
    "    json.dump(glove_dictionary, f)\n",
    "\n",
    "with open('../data/processed/frames/v3/glove_vectors.json', 'w') as f:\n",
    "    json.dump(np.array(embeddings).tolist(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1060,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for frame in frames[:10]:\n",
    "    turns = frame['turns']\n",
    "    frame_authors = ['user']\n",
    "    created_frame_ids = {0: [0]}\n",
    "    for previous_turn_id, turn in enumerate(turns[1:]):\n",
    "        previous_frames_count = len(turns[previous_turn_id].get('labels', {}).get('frames', []))\n",
    "        frames_count = len(turn.get('labels', {}).get('frames', []))\n",
    "        \n",
    "        if frames_count > previous_frames_count:\n",
    "            frame_authors.extend([turn['author']]*(frames_count - previous_frames_count))\n",
    "            created_frame_ids[previous_turn_id+1] = list(range(previous_frames_count, frames_count))\n",
    "    assert len(frame_authors) == len(turns[-1].get('labels', {}).get('frames', []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1048,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user']"
      ]
     },
     "execution_count": 1048,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import calendar\n",
    "import spacy\n",
    "en_nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1071,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def parse_frame(frame):\n",
    "    result = {}\n",
    "    for (key, values) in frame.items():\n",
    "        result[key] = values[-1]['val']\n",
    "    return result\n",
    "\n",
    "def format_db_date(date):\n",
    "    return '{0} {1} {2}'.format(date.get('day'), calendar.month_name[date.get('month')], date.get('year'))\n",
    "\n",
    "def parse_db_item(item):\n",
    "    item_parsed = {}\n",
    "    for (key, value) in item.items():\n",
    "        if (not isinstance(value, (dict, list))) and (key in slots_dictionary):\n",
    "            item_parsed[key] = value\n",
    "    for (key, value) in item.get('trip', {}).items():\n",
    "        key = key.replace('_days', '')\n",
    "        if (not isinstance(value, (dict, list))) and (key in slots_dictionary):\n",
    "            item_parsed[key] = value\n",
    "        if key == 'leaving':\n",
    "            item_parsed['str_date'] = format_db_date(value.get('departure', {}))\n",
    "        if key == 'returning':\n",
    "            item_parsed['end_date'] = format_db_date(value.get('departure', {}))\n",
    "    for (key, value) in item.get('hotel', {}).items():\n",
    "        if (not isinstance(value, (dict, list))) and (key in slots_dictionary):\n",
    "            item_parsed[key] = value\n",
    "        if key == 'amenities':\n",
    "            for amenity in value:\n",
    "                amenity_name = amenity.replace('FREE_', '').lower()\n",
    "                if amenity_name in slots_dictionary:\n",
    "                    item_parsed[amenity_name] = True\n",
    "            \n",
    "    return item_parsed\n",
    "\n",
    "def slot_state(value):\n",
    "    value = str(value)\n",
    "    if value == '-1':\n",
    "        return 'any'\n",
    "    if value == 'True':\n",
    "        return 'true'\n",
    "    if value == 'False':\n",
    "        return 'false'\n",
    "    if len(value) > 0:\n",
    "        return 'expressed'\n",
    "    return pad    \n",
    "\n",
    "def parse_turn(turn_idx, turn, previous_turn, next_turn, previous_context, previous_database_results, frame_authors, previous_created_frame_ids):\n",
    "    # User input acts targets parsing\n",
    "    updated_context = previous_context.copy()\n",
    "    informable_slots_values, informable_slots_boolean_values, requestable_slots = {}, {}, set()\n",
    "    slot_states = {}\n",
    "    for act in turn.get('labels').get('acts_without_refs', []):\n",
    "        if act['name'] == 'inform':\n",
    "            for arg in act['args']:\n",
    "                slot_states[arg.get('key')] = slot_state(arg.get('val'))\n",
    "                if arg.get('key') in value_slots:\n",
    "                    for token in nltk.word_tokenize(str(arg.get('val')).lower()):\n",
    "                        informable_slots_values[token] = arg.get('key')\n",
    "                if arg.get('key') in boolean_slots:\n",
    "                    informable_slots_boolean_values[arg['key']] = arg.get('val')\n",
    "                updated_context[arg.get('key')] = arg.get('val')\n",
    "        if act['name'] == 'request':\n",
    "            for arg in act['args']:\n",
    "                requestable_slots.add(arg['key'])\n",
    "                \n",
    "    previous_frames = previous_turn.get('labels', {}).get('frames')\n",
    "    current_frames = turn.get('labels', {}).get('frames', [])\n",
    "                \n",
    "    # Agent action parsing\n",
    "    agent_actions, agent_sub_actions = set(), set()\n",
    "    response_delexicalization_terms = []\n",
    "    for act in next_turn.get('labels', {}).get('acts', []):\n",
    "        agent_actions.add(act['name'])\n",
    "        if act['name'] in {'inform', 'offer', 'suggest', 'no_result'}:\n",
    "            for arg in act['args']:\n",
    "                if arg['key'] == 'id':\n",
    "                    continue\n",
    "                if arg['key'] in {'ref', 'read', 'write'}:\n",
    "                    for v in arg['val']:\n",
    "                        response_delexicalization_terms.extend(v['annotations'])\n",
    "                else:\n",
    "                    response_delexicalization_terms.append(arg)\n",
    "        if act['name'] in {'inform', 'request', 'suggest', 'offer'}:\n",
    "            for arg in act['args']:\n",
    "                if arg['key'] in slots_dictionary:\n",
    "                    agent_sub_actions.add('{0}.{1}'.format(act['name'], arg['key']))\n",
    "     \n",
    "    delexicalized_response = next_turn.get('text', '')\n",
    "    for term in response_delexicalization_terms:\n",
    "        if (term.get('val') is not None) and (term.get('key') in value_slots):\n",
    "            delexicalized_response = delexicalized_response.replace(term.get('val'), 'SLOT.{0}'.format(term.get('key')))\n",
    "\n",
    "    # Parse frames\n",
    "    raw_input_frames = sorted(previous_turn.get('labels', {}).get('frames', []), key=lambda f: f['frame_id'])\n",
    "    input_frames = []\n",
    "    for frame in raw_input_frames:\n",
    "        parsed_frame = parse_frame(frame.get('info', {}))\n",
    "        if frame.get('frame_parent_id') is not None:\n",
    "            parsed_parent = parse_frame(raw_input_frames[int(frame.get('frame_parent_id'))-1].get('info', {}))\n",
    "            parsed_frame = dict(parsed_frame, **parsed_parent)\n",
    "        input_frames.append(parsed_frame)\n",
    "    input_frame_authors = frame_authors[:len(input_frames)]\n",
    "        \n",
    "    raw_output_frames = sorted(turn.get('labels', {}).get('frames', []), key=lambda f: f['frame_id'])    \n",
    "    output_frames = []\n",
    "    for frame in raw_output_frames:\n",
    "        parsed_frame = parse_frame(frame.get('info', {}))\n",
    "        if frame.get('frame_parent_id') is not None:\n",
    "            parsed_parent = parse_frame(raw_output_frames[int(frame.get('frame_parent_id'))-1].get('info', {}))\n",
    "            parsed_frame = dict(parsed_frame, **parsed_parent)\n",
    "        output_frames.append(parsed_frame)\n",
    "\n",
    "    # Parse database result\n",
    "    db_results = next_turn.get('db', {}).get('result', [])\n",
    "    db_search = next_turn.get('db', {}).get('search', [])\n",
    "    database_results = []\n",
    "    if len(db_results) > 0:\n",
    "        for db_item in db_results[0]:\n",
    "            parsed_db_item = parse_db_item(db_item)\n",
    "            database_results.append(parsed_db_item)\n",
    "    if not((len(database_results) > 0) or (len(db_search) > 0)):\n",
    "        database_results = previous_database_results\n",
    "    if 'no_result' in agent_actions:\n",
    "        database_results = []\n",
    "        \n",
    "    active_frame_id = turn.get('labels', {}).get('active_frame', 1) - 1\n",
    "    previous_active_frame_id = previous_turn.get('labels', {}).get('active_frame', 1) - 1\n",
    "    referenced_frame = output_frames[active_frame_id]\n",
    "    \n",
    "    return {\n",
    "        'current_turn_text': turn['text'],\n",
    "        'previous_agent_text': previous_turn.get('text', ''),\n",
    "        'next_agent_text': next_turn.get('text', ''),\n",
    "        'next_agent_text_delexicalized': delexicalized_response,\n",
    "        'user_informed_value_slots': [informable_slots_values.get(token, '<NO_SLOT>') for token in nltk.word_tokenize(str(turn['text']).lower())],\n",
    "        'user_informed_bool_slots': informable_slots_boolean_values,\n",
    "        'user_informed_slot_states': slot_states,\n",
    "        'user_requested_slots': list(requestable_slots),\n",
    "        'active_frame_id': active_frame_id,\n",
    "        'previous_active_frame_id': previous_active_frame_id,\n",
    "        'input_frames': input_frames,\n",
    "        'input_frame_authors': input_frame_authors,\n",
    "        'input_frame_recently_created': previous_created_frame_ids.get(turn_idx-1, []),\n",
    "        'referenced_frame': referenced_frame,\n",
    "        'input_context': previous_context,\n",
    "        'agent_actions': sorted(agent_actions),\n",
    "        'agent_sub_actions': sorted(agent_sub_actions),\n",
    "        'database_results': database_results,\n",
    "        'database_results_count': len(database_results)\n",
    "    }, updated_context, database_results\n",
    "\n",
    "turns_parsed = []\n",
    "for dialog in frames:\n",
    "    turns = dialog['turns']\n",
    "    # Get frame authors\n",
    "    frame_authors = ['user']\n",
    "    created_frame_ids = {0: [0]}\n",
    "    for previous_turn_id, turn in enumerate(turns[1:]):\n",
    "        previous_frames_count = len(turns[previous_turn_id].get('labels', {}).get('frames', []))\n",
    "        frames_count = len(turn.get('labels', {}).get('frames', []))\n",
    "        \n",
    "        if frames_count > previous_frames_count:\n",
    "            frame_authors.extend([turn['author']]*(frames_count - previous_frames_count))\n",
    "            created_frame_ids[previous_turn_id+1] = list(range(previous_frames_count, frames_count))\n",
    "    assert len(frame_authors) == len(turns[-1].get('labels', {}).get('frames', []))\n",
    "    \n",
    "    # Parse turns\n",
    "    context = {}\n",
    "    database_results = []\n",
    "    for turn_idx, turn in enumerate(turns):\n",
    "        if turn['author'] == 'wizard':\n",
    "            continue\n",
    "\n",
    "        if turn_idx == 0:\n",
    "            previous_turn = {}\n",
    "        else:\n",
    "            previous_turn = turns[turn_idx-1]\n",
    "            \n",
    "        if turn_idx == len(turns)-1:\n",
    "            next_turn = {}\n",
    "        else:\n",
    "            next_turn = turns[turn_idx+1]\n",
    "            \n",
    "        parsed, context, database_results = parse_turn(turn_idx, turn, previous_turn, next_turn, context, database_results, frame_authors, created_frame_ids)\n",
    "        turns_parsed.append(parsed)\n",
    "#         print(parsed['previous_agent_text'])\n",
    "#         print(parsed['current_turn_text'])\n",
    "#         print(parsed['input_frame_authors'], len(parsed['input_frames']))\n",
    "#         print(parsed['input_frame_recently_created'])\n",
    "#         print(parsed['next_agent_text'])\n",
    "#         print(parsed['agent_actions'])\n",
    "#         print(parsed['agent_sub_actions'])\n",
    "#         print('Agent:', parsed['previous_agent_text'])\n",
    "#         print('User:', parsed['current_turn_text'])\n",
    "#         print(parsed['user_informed_slot_states'])\n",
    "#         for frame in parsed['input_frames']:\n",
    "#             print(frame)\n",
    "#             print()\n",
    "#         print('Referenced:', parsed['referenced_frame'])\n",
    "#         print('Previous active frame:', parsed['previous_active_frame_ids'])\n",
    "#         print('Referenced frame:', parsed['current_active_frame_ids'])\n",
    "#         print('Agent:', parsed['next_agent_text'])\n",
    "#         print(parsed['agent_action'])\n",
    "#         print(parsed['database_results_count'])\n",
    "#         print('---------------- TURN ---------------')\n",
    "#     print('------------------- DIALOG ---------------------')\n",
    "        \n",
    "\n",
    "with open('../data/processed/frames/v3/turns_parsed.json', 'w') as f:\n",
    "    json.dump(turns_parsed, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1088,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] []\n",
      "Frame: 0 \n",
      "Frame: 0 I'd like to book a trip to Atlantis from Caprica on Saturday, August 13, 2016 for 8 adults. I have a tight budget of 1700.\n",
      "---------\n",
      "['user'] []\n",
      "Frame: 0 Hi...I checked a few options for you, and unfortunately, we do not currently have any trips that meet this criteria.  Would you like to book an alternate travel option?\n",
      "Frame: 1 Yes, how about going to Neverland from Caprica on August 13, 2016 for 5 adults. For this trip, my budget would be 1900.\n",
      "---------\n",
      "['user', 'user'] []\n",
      "Frame: 1 I checked the availability for this date and there were no trips available.  Would you like to select some alternate dates?\n",
      "Frame: 2 I have no flexibility for dates... but I can leave from Atlantis rather than Caprica. How about that?\n",
      "---------\n",
      "['user', 'user', 'user'] []\n",
      "Frame: 2 I checked the availability for that date and there were no trips available.  Would you like to select some alternate dates?\n",
      "Frame: 2 I suppose I'll speak with my husband to see if we can choose other dates, and then I'll come back to you.Thanks for your help\n",
      "---------\n",
      "[] []\n",
      "Frame: 0 \n",
      "Frame: 0 Hello, I am looking to book a vacation from Gotham City to Mos Eisley for $2100.\n",
      "---------\n",
      "['user'] []\n",
      "Frame: 0 Hi. Sorry, I can't find any trips from Gotham City to Mos Eisley for you.\n",
      "Frame: 1 What about a trip from Gotham City to Neverland for the same budget?\n",
      "---------\n",
      "['user', 'user'] []\n",
      "Frame: 1 Sorry, I cannot find any trips leaving from Gotham City. Could you suggest another nearby departure city?\n",
      "Frame: 2 Would any packages to Mos Eisley be available if I increase my budget to $2500?\n",
      "---------\n",
      "['user', 'user', 'user'] []\n",
      "Frame: 2 There are no trips available to Mos Eisley.\n",
      "Frame: 3 You know what, I'd like to try and visit Neverland\n",
      "---------\n",
      "['user', 'user', 'user', 'user'] []\n",
      "Frame: 3 I cannot find any trips available to Neverland.\n",
      "Frame: 4 Do you have any trips from Gotham City to Kobe for my original budget of $2100?\n",
      "---------\n",
      "['user', 'user', 'user', 'user', 'user', 'wizard'] [5]\n",
      "Frame: 4 I can book you a 3 day trip to Kobe leaving from Sapporo, Japan. Is this ok?\n",
      "Frame: 6 No, that's too far for me. I need a flight that leaves from Birmingham.\n",
      "---------\n",
      "['user', 'user', 'user', 'user', 'user', 'wizard', 'user', 'wizard'] [7]\n",
      "Frame: 6 I can book you a trip from Birmingham to Kobe for 2747.8 USD.\n",
      "Frame: 7 How many days would I be in Kobe?\n",
      "---------\n",
      "['user', 'user', 'user', 'user', 'user', 'wizard', 'user', 'wizard'] []\n",
      "Frame: 7 You would arrive in Kobe August 17th and return to Birmingham on August 22nd.\n",
      "Frame: 8 What would the price be if I shortened my trip by one day?\n",
      "---------\n",
      "['user', 'user', 'user', 'user', 'user', 'wizard', 'user', 'wizard', 'user'] []\n",
      "Frame: 8 I can not find any trips from Birmingham to Kobe for 4 days.\n",
      "Frame: 7 Ok, then I would like to purchase this package. What activities are included in this package?\n",
      "---------\n",
      "['user', 'user', 'user', 'user', 'user', 'wizard', 'user', 'wizard', 'user'] []\n",
      "Frame: 7 There are no activities listed for this package. You will be staying at the Ivory Legacy Hotel for 7 days. This hotel has a 4.5 star rating and free wifi. Will I go ahead and book this package?\n",
      "Frame: 7 Yes, I would like to book this package.\n",
      "---------\n",
      "[] []\n",
      "Frame: 0 \n",
      "Frame: 0 Hello there i am looking to go on a vacation with my family to Gotham City, can you help me?\n",
      "---------\n",
      "['user'] []\n",
      "Frame: 0 when  would you like to travel and how many people will you be?\n",
      "Frame: 0 Not sure when we want to leave, but we are 12 kids and 5 adults\n",
      "---------\n",
      "['user'] []\n",
      "Frame: 0 do you have a budget?\n",
      "Frame: 0 yes i do, it is around $2200\n",
      "---------\n",
      "['user'] []\n",
      "Frame: 0 where will you be travelling from?\n",
      "Frame: 0 We are from Neverland\n",
      "---------\n",
      "['user'] []\n",
      "Frame: 0 We have nothing available leaving from Neverland, are you able to depart from another city?\n",
      "Frame: 1 we can depart from Toronto\n",
      "---------\n",
      "['user', 'user'] []\n",
      "Frame: 1 Gotham City is not a destination we travel to. Are you interested in any other destinations?\n",
      "Frame: 2 hmm what options would i have out of Toronto?\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "for turn in turns_parsed[:20]:\n",
    "    print(turn['input_frame_authors'], turn['input_frame_recently_created'])\n",
    "    print('Frame:', turn['previous_active_frame_id'], turn['previous_agent_text'])\n",
    "    print('Frame:', turn['active_frame_id'], turn['current_turn_text'])\n",
    "    print('---------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1076,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "SLOT_STATES = {\n",
    "    'pad': 0,\n",
    "    'expressed': 1,\n",
    "    'any': 2,\n",
    "    'true': 3,\n",
    "    'false': 4\n",
    "}\n",
    "\n",
    "FRAME_AUTHORS = {\n",
    "    'user': 0,\n",
    "    'wizard': 1\n",
    "}\n",
    "\n",
    "def embed_delexicalized(text):\n",
    "    embedded = []\n",
    "    for token in nltk.word_tokenize(str(text).lower()):\n",
    "        if re.match('slot+\\.[a-z_]+', token):\n",
    "            embedded.append(glove_dictionary.get('<SLOT.{0}>'.format(token.split('.')[1]), 2))\n",
    "            continue\n",
    "        embedded.append(glove_dictionary.get(token, 2))\n",
    "    return embedded\n",
    "\n",
    "def string_embedding_ids(text):\n",
    "    return [glove_dictionary.get(token, 2) for token in nltk.word_tokenize(str(text).lower())]\n",
    "\n",
    "def embed_bool_value(value):\n",
    "    key = '<VAL.{0}>'.format(str(value).lower())\n",
    "    return glove_dictionary.get(key, 2)\n",
    "\n",
    "def embed_complex(struct):\n",
    "    embedded = {}\n",
    "    for (slot, value) in struct.items():\n",
    "        if slot in value_slots:\n",
    "            embedded[slots_dictionary.get(slot, 0)] = string_embedding_ids(value)\n",
    "        elif slot in boolean_slots:\n",
    "            embedded[slots_dictionary.get(slot, 0)] = [embed_bool_value(value)]\n",
    "    return embedded\n",
    "\n",
    "def embed_turn(turn):\n",
    "    return {\n",
    "        'user_input_embedding_ids': string_embedding_ids(turn['current_turn_text']),\n",
    "        'previous_agent_embedding_ids': string_embedding_ids(turn['previous_agent_text']),\n",
    "        'next_agent_embedding_ids': string_embedding_ids(turn['next_agent_text']),\n",
    "        'next_agent_delexicalized_embedding_ids': embed_delexicalized(turn['next_agent_text_delexicalized']),\n",
    "        'user_informed_value_slot_ids': [slots_dictionary.get(slot, 0) for slot in turn['user_informed_value_slots']],\n",
    "        'user_informed_bool_slot_ids': {slots_dictionary.get(slot, 0): [int(value)+1] for (slot, value) in turn['user_informed_bool_slots'].items()},\n",
    "        'user_informed_slot_state_ids': {slots_dictionary.get(slot, 0): SLOT_STATES.get(state, 0) for (slot, state) in turn['user_informed_slot_states'].items()},\n",
    "        'user_requested_slot_ids': [slots_dictionary.get(slot, 0) for slot in turn['user_requested_slots']],\n",
    "        'active_frame_id': turn['active_frame_id'],\n",
    "        'previous_active_frame_id': turn['previous_active_frame_id'],\n",
    "        'input_frames_embedded': [embed_complex(frame) for frame in turn['input_frames']],\n",
    "        'input_frame_authors': [FRAME_AUTHORS[author] for author in turn['input_frame_authors']],\n",
    "        'input_frame_recently_created': turn['input_frame_recently_created'],\n",
    "        'referenced_frame_embedded': embed_complex(turn['referenced_frame']),\n",
    "        'input_context_embedded': embed_complex(turn['input_context']),\n",
    "        'agent_action_ids': [agent_actions_dictionary.get(action, 0) for action in turn['agent_actions']],\n",
    "        'agent_sub_action_ids': [agent_sub_actions_dictionary.get(sub_action, 0) for sub_action in turn['agent_sub_actions']],\n",
    "        'database_results_embedded': [embed_complex(item) for item in turn['database_results']],\n",
    "        'database_results_count': turn['database_results_count']\n",
    "    }\n",
    "\n",
    "turns_embedded = []\n",
    "for turn in turns_parsed:\n",
    "    turns_embedded.append(embed_turn(turn))\n",
    "            \n",
    "assert len(turns_embedded) == len(turns_parsed)\n",
    "with open('../data/processed/frames/v3/turns_embedded.json', 'w') as f:\n",
    "    json.dump(turns_embedded, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "turns_embedded_shuffled = turns_embedded.copy()\n",
    "random.shuffle(turns_embedded_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1, 3: 1, 5: 1, 30: 1, 38: 1, 49: 1}"
      ]
     },
     "execution_count": 1077,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turns_embedded[0]['user_informed_slot_state_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1078,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_size = int(len(turns_embedded)*0.85)\n",
    "\n",
    "with open('../data/processed/frames/v3/turns_train.json', 'w') as f:\n",
    "    json.dump(turns_embedded[:train_size], f)\n",
    "with open('../data/processed/frames/v3/turns_test.json', 'w') as f:\n",
    "    json.dump(turns_embedded[train_size:], f)\n",
    "# with open('../data/processed/frames/v2/turns_train_shuffled.json', 'w') as f:\n",
    "#     json.dump(turns_embedded_shuffled[:train_size], f)\n",
    "# with open('../data/processed/frames/v2/turns_test_shuffled.json', 'w') as f:\n",
    "#     json.dump(turns_embedded_shuffled[train_size:], f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
