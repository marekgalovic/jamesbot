{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# JamesBot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Language understanding module (LU):**\n",
    "- inputs:\n",
    "    - sequence of token embeddings\n",
    "- outputs:\n",
    "    - final encoder state\n",
    "    - sequence of token representations (bi-rnn encoded)\n",
    "\n",
    "**Informable slots recognizer:**\n",
    "- inputs:\n",
    "    - current utterance LU outputs\n",
    "- outputs:\n",
    "    - probability distribution that a token puts a constraint on a slot.\n",
    "    - probability distribution that an utterance puts a constraint on a slot.\n",
    "    \n",
    "**Requestable slots recognizer:**\n",
    "- inputs:\n",
    "    - current utterance LU outputs\n",
    "- outputs:\n",
    "    - probability distribution that an user requests information about a slot.\n",
    "    \n",
    "**Frame tracker:**\n",
    "- inputs:\n",
    "    - LU states\n",
    "    - informable slots constraints for every utterance\n",
    "    - requestable slots for every utterance\n",
    "- outputs:\n",
    "    - intent vector (compare, inform, request, offer, confirm, book ...)\n",
    "    - slot constraints vector\n",
    "    - frame reference vector\n",
    "    \n",
    "- for every act give me a probability that it references utterance\n",
    "    \n",
    "**Belief tracker:**\n",
    "- inputs:\n",
    "    - current utterance LU outputs\n",
    "    - previous utterance LU outputs\n",
    "    - informable slots constraints p for current utterance\n",
    "    - requestable slots p for current utterance\n",
    "- outputs:\n",
    "    - intent vector (inform, request, offer, confirm, book ...)\n",
    "    - updated slot constraints vector (probability that user has expressed a constraint on the slot during the    dialogue)\n",
    "- state:\n",
    "    - slot constraints vector\n",
    "\n",
    "**Query engine:**\n",
    "- inputs:\n",
    "    - slot constraints vector\n",
    "    - informable slots recognizer p\n",
    "- output:\n",
    "    - updated KB results pointer\n",
    "- state:\n",
    "    - KB results pointer (probability distribution over results) -> argmax is the current one\n",
    "\n",
    "**Agent policy:**\n",
    "- inputs:\n",
    "    - current utterance bi-rnn outputs/state\n",
    "    - intent vector\n",
    "    - requestable slots recognizer p\n",
    "    - slot constraints vector\n",
    "    - KB results pointer\n",
    "- outputs:\n",
    "    - dialog state vector\n",
    "    \n",
    "**Language generation module (LG):**\n",
    "- inputs:\n",
    "    - LU outputs/state\n",
    "    - dialog state vector\n",
    "- outputs:\n",
    "    - sequence of probability distributions over tokens/placeholders in dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1471,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('../data/processed/frames/v3/turns_train.json') as f:\n",
    "    turns_train = json.load(f)\n",
    "with open('../data/processed/frames/v3/turns_test.json') as f:\n",
    "    turns_test = json.load(f)\n",
    "with open('../data/processed/frames/v3/glove_vectors.json') as f:\n",
    "    embeddings = np.array(json.load(f))\n",
    "with open('../data/processed/frames/v3/glove_dictionary.json') as f:\n",
    "    glove_dictionary = json.load(f)\n",
    "with open('../data/processed/frames/v3/slots_dictionary.json') as f:\n",
    "    slots_dictionary = json.load(f)\n",
    "with open('../data/processed/frames/v3/agent_actions_dictionary.json') as f:\n",
    "    agent_actions_dictionary = json.load(f)\n",
    "with open('../data/processed/frames/v3/agent_sub_actions_dictionary.json') as f:\n",
    "    agent_sub_actions_dictionary = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1346,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "slots_index = {val: key for (key, val) in slots_dictionary.items()}\n",
    "glove_index = {val: key for (key, val) in glove_dictionary.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Samples padding/iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1512,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def pad_sequences(sequences, max_len, pad_value=0):\n",
    "    '''\n",
    "    :param sequences: An array of arrays of different lengths that will be padded to [len(sequences) x max_len] matrix\n",
    "    '''\n",
    "    result = []\n",
    "    for sequence in sequences:\n",
    "        if len(sequence) < max_len:\n",
    "            result.append(sequence + [pad_value]*(max_len - len(sequence)))\n",
    "        if len(sequence) >= max_len:\n",
    "            result.append(sequence[:max_len])\n",
    "    return np.array(result, dtype=np.int32)\n",
    "\n",
    "def pad_complex(struct, max_keys_len, max_values_len, pad_value=0, shuffle=True):\n",
    "    '''\n",
    "    :param struct: Dictionary of arrays. \n",
    "    :returns: Vector of slot indices, matrix of value indices, number of slots and a vector of value lengths.\n",
    "    '''\n",
    "    if len(struct) == 0:\n",
    "        return (\n",
    "            np.zeros(shape=(max_keys_len), dtype=np.int32),\n",
    "            np.zeros(shape=(max_keys_len, max_values_len), dtype=np.int32)\n",
    "        )\n",
    "    \n",
    "    struct_items = list(struct.items())\n",
    "    if shuffle == True:\n",
    "        random.shuffle(struct_items)\n",
    "        \n",
    "    keys, values = [], []\n",
    "    for (key, value) in struct_items:\n",
    "        keys.append(key)\n",
    "        values.append(value)\n",
    "    if len(keys) < max_keys_len:\n",
    "        keys += [pad_value]*(max_keys_len-len(keys))\n",
    "        values += [[pad_value]]*(max_keys_len-len(values))\n",
    "    \n",
    "    return (\n",
    "        np.array(keys).astype(int),\n",
    "        pad_sequences(values, max_values_len)\n",
    "    )\n",
    "\n",
    "def pad_array_of_complex(structs, max_keys_count, max_values_length):\n",
    "    '''\n",
    "    :param structs: An array of structs\n",
    "    :returns: Padded keys, values, struct sizes and value lengths\n",
    "    '''\n",
    "    if len(structs) == 0:\n",
    "        return (\n",
    "            np.zeros(shape=(1,max_keys_count), dtype=np.int32),\n",
    "            np.zeros(shape=(1,max_keys_count,max_values_length), dtype=np.int32),\n",
    "            np.zeros(shape=(1,), dtype=np.int32),\n",
    "            np.zeros(shape=(1,max_keys_count), dtype=np.int32)\n",
    "        )\n",
    "    key_counts = [len(struct) for struct in structs]\n",
    "    value_lengths = [[len(value) for (_, value) in struct.items()] for struct in structs]\n",
    "    \n",
    "    keys_padded, values_padded = [], []\n",
    "    for struct in structs:\n",
    "        keys, values = pad_complex(struct, max_keys_count, max_values_length)\n",
    "        keys_padded.append(keys)\n",
    "        values_padded.append(values)\n",
    "    \n",
    "    keys_padded = np.array(keys_padded, dtype=np.int32)\n",
    "    values_padded = np.array(values_padded, dtype=np.int32)\n",
    "    \n",
    "    for i in range(len(structs)):\n",
    "        if len(value_lengths[i]) < max_keys_count:\n",
    "            value_lengths[i] += [0]*(max_keys_count-len(value_lengths[i]))\n",
    "            \n",
    "    return (\n",
    "        keys_padded,\n",
    "        values_padded,\n",
    "        np.array(key_counts, dtype=np.int32),\n",
    "        np.array(value_lengths, dtype=np.int32)\n",
    "    )\n",
    "\n",
    "def pad_nested_array_of_complex(frames_batch):\n",
    "    frames_counts, frames_slot_counts, frames_value_lengths = [], [], []\n",
    "    for frames in frames_batch:\n",
    "        frames_counts.append(len(frames))\n",
    "        for frame in frames:\n",
    "            frames_slot_counts.append(len(frame))\n",
    "            frames_value_lengths.extend([len(value) for (_, value) in frame.items()])\n",
    "    max_frames_count = max(frames_counts)\n",
    "    max_slots_count = max(frames_slot_counts)\n",
    "    max_values_length = max(frames_value_lengths)\n",
    "    \n",
    "    frames_batch_slots, frames_batch_values, frames_batch_key_counts, frames_batch_value_lengths = [], [], [], []\n",
    "    for frames in frames_batch:\n",
    "        slots, values, key_counts, value_lengths = pad_array_of_complex(frames, max_slots_count, max_values_length)\n",
    "        if len(slots) < max_frames_count:\n",
    "            slots_pad = np.zeros(shape=(max_frames_count-len(slots),max_slots_count), dtype=np.int32)\n",
    "            slots = np.append(slots, slots_pad, axis=0)\n",
    "        if len(values) < max_frames_count:\n",
    "            values_pad = np.zeros(shape=(max_frames_count-len(values),max_slots_count,max_values_length), dtype=np.int32)\n",
    "            values = np.append(values, values_pad, axis=0)\n",
    "        if len(key_counts) < max_frames_count:\n",
    "            key_counts_pad = np.zeros(shape=(max_frames_count-len(key_counts)), dtype=np.int32)\n",
    "            key_counts = np.append(key_counts, key_counts_pad, axis=0)\n",
    "        if len(value_lengths) < max_frames_count:\n",
    "            value_lengths_pad = np.zeros(shape=(max_frames_count-len(value_lengths),max_slots_count), dtype=np.int32)\n",
    "            value_lengths = np.append(value_lengths, value_lengths_pad, axis=0)\n",
    "        frames_batch_slots.append(slots)\n",
    "        frames_batch_values.append(values)\n",
    "        frames_batch_key_counts.append(key_counts),\n",
    "        frames_batch_value_lengths.append(value_lengths)\n",
    "        \n",
    "    return (\n",
    "        np.array(frames_batch_slots, dtype=np.int32),\n",
    "        np.array(frames_batch_values, dtype=np.int32),\n",
    "        np.array(frames_batch_key_counts, dtype=np.int32),\n",
    "        np.array(frames_batch_value_lengths, dtype=np.int32)\n",
    "    )\n",
    "\n",
    "def pad_complex_categorical(structs, n_categories):\n",
    "    result = np.zeros([len(structs), n_categories], dtype=np.int32)\n",
    "    for idx, struct in enumerate(structs):\n",
    "        if len(struct) > 0:\n",
    "            for (category_idx, value) in struct.items():\n",
    "                result[idx, int(category_idx)] = int(value)\n",
    "    return result\n",
    "\n",
    "def pad_turns(turns, n_slots=51):\n",
    "    user_inputs_batch = [turn['user_input_embedding_ids'] for turn in turns]\n",
    "    user_inputs_lengths = list(map(len, user_inputs_batch))\n",
    "    previous_responses_batch = [turn['previous_agent_embedding_ids'] for turn in turns]\n",
    "    previous_responses_lengths = list(map(len, previous_responses_batch))\n",
    "    next_responses_batch = [turn['next_agent_delexicalized_embedding_ids'] + [1] for turn in turns]\n",
    "    next_responses_lengths = list(map(len, next_responses_batch))\n",
    "    \n",
    "    user_informed_value_slots_batch = [turn['user_informed_value_slot_ids'] for turn in turns]\n",
    "    user_informed_slot_states_batch = [turn['user_informed_slot_state_ids'] for turn in turns]\n",
    "\n",
    "    frames_counts = [len(turn['input_frames_embedded']) for turn in turns]\n",
    "    frames_authors_batch = [turn['input_frame_authors'] for turn in turns]\n",
    "    frames_recently_created_batch = [turn['input_frame_recently_created'] for turn in turns]\n",
    "    frames_slots, frames_values, frames_slot_counts, frames_value_lengths = pad_nested_array_of_complex([turn['input_frames_embedded'] for turn in turns])\n",
    "    db_result_counts = [turn['database_results_count'] for turn in turns]\n",
    "    \n",
    "    referenced_frames_batch = [turn['referenced_frame_embedded'] for turn in turns]\n",
    "    referenced_frame_slots, referenced_frame_values, referenced_frame_slot_counts, referenced_frame_value_lengths = pad_array_of_complex(\n",
    "        referenced_frames_batch,\n",
    "        max(map(len, referenced_frames_batch)),\n",
    "        max([len(value) for frame in referenced_frames_batch for (_, value) in frame.items()])\n",
    "    )\n",
    "    \n",
    "    previous_active_frames_batch = [turn['previous_active_frame_id'] for turn in turns]\n",
    "    current_active_frames_batch = [turn['active_frame_id'] for turn in turns]\n",
    "    \n",
    "    agent_actions_batch = [turn['agent_action_ids'] for turn in turns]\n",
    "    agent_sub_actions_batch = [turn['agent_sub_action_ids'] for turn in turns]\n",
    "    \n",
    "    return {\n",
    "        'user_inputs': pad_sequences(user_inputs_batch, max(user_inputs_lengths)),\n",
    "        'user_input_lengths': np.array(user_inputs_lengths, dtype=np.int32),\n",
    "        'previous_responses': pad_sequences(previous_responses_batch, max(previous_responses_lengths)),\n",
    "        'previous_response_lengths': np.array(previous_responses_lengths, dtype=np.int32),\n",
    "        'next_responses': pad_sequences(next_responses_batch, max(next_responses_lengths)),\n",
    "        'next_response_lengths': np.array(next_responses_lengths, dtype=np.int32),\n",
    "        'user_informed_value_slots': pad_sequences(user_informed_value_slots_batch, max(user_inputs_lengths)),\n",
    "        'user_informed_slot_states': pad_complex_categorical(user_informed_slot_states_batch, n_slots),\n",
    "        'frames_counts': np.array(frames_counts, dtype=np.int32),\n",
    "        'frames_slots': frames_slots,\n",
    "        'frames_values': frames_values,\n",
    "        'frames_slot_counts': frames_slot_counts,\n",
    "        'frames_value_lengths': frames_value_lengths,\n",
    "        'frames_authors': pad_sequences(frames_authors_batch, max(map(len, frames_authors_batch)), pad_value=-1),\n",
    "        'frames_recently_created': pad_sequences(frames_recently_created_batch, max(map(len, frames_recently_created_batch)), pad_value=-1),\n",
    "        'referenced_frame_slots': referenced_frame_slots,\n",
    "        'referenced_frame_values': referenced_frame_values,\n",
    "        'referenced_frame_slot_counts': referenced_frame_slot_counts,\n",
    "        'referenced_frame_value_lengths': referenced_frame_value_lengths,\n",
    "        'previous_active_frames': np.array(previous_active_frames_batch, dtype=np.int32),\n",
    "        'current_active_frames': np.array(current_active_frames_batch, dtype=np.int32),\n",
    "        'db_result_counts': np.array(db_result_counts, dtype=np.int32),\n",
    "        'agent_actions': pad_sequences(agent_actions_batch, max(map(len, agent_actions_batch)), pad_value=-1),\n",
    "        'agent_sub_actions': pad_sequences(agent_sub_actions_batch, max(map(len, agent_sub_actions_batch)), pad_value=-1),\n",
    "    }\n",
    "\n",
    "def samples_iterator(data, batch_size=64, max_len=50):\n",
    "    for i in range(int(len(data)/batch_size)):\n",
    "        rows = data[i*batch_size:i*batch_size+batch_size]\n",
    "        \n",
    "        yield pad_turns(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1513,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUTS:\n",
      "User inputs: (64, 31) lengths: (64,)\n",
      "Previous responses: (64, 52) lengths: (64,)\n",
      "Next responses: (64, 53) lengths: (64,)\n",
      "Frames counts: (64,)\n",
      "Frames slots: (64, 9, 13)\n",
      "Frames values: (64, 9, 13, 4)\n",
      "Frames slot counts: (64, 9)\n",
      "Frames value lengths: (64, 9, 13)\n",
      "Frames authors: (64, 9)\n",
      "Frames recently created: (64, 3)\n",
      "Referenced frame slots: (64, 13)\n",
      "Referenced frame values: (64, 13, 4)\n",
      "Referenced frame slot counts: (64,)\n",
      "Referenced frame value lengths: (64, 13)\n",
      "DB result counts: (64,)\n",
      "TARGETS:\n",
      "Informed value slots: (64, 31)\n",
      "Informed slot states: (64, 51)\n",
      "Previous active frame: (64,)\n",
      "Current active frame: (64,)\n",
      "Agent actions: (64, 3)\n",
      "Agent sub actions: (64, 8)\n",
      "22.220849990844727 ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_at = time.time()\n",
    "\n",
    "for i, batch in enumerate(samples_iterator(turns_train)):\n",
    "    print('INPUTS:')\n",
    "    print('User inputs:', batch['user_inputs'].shape, 'lengths:', batch['user_input_lengths'].shape)\n",
    "    print('Previous responses:', batch['previous_responses'].shape, 'lengths:', batch['previous_response_lengths'].shape)\n",
    "    print('Next responses:', batch['next_responses'].shape, 'lengths:', batch['next_response_lengths'].shape)\n",
    "    print('Frames counts:', batch['frames_counts'].shape)\n",
    "    print('Frames slots:', batch['frames_slots'].shape)\n",
    "    print('Frames values:', batch['frames_values'].shape)\n",
    "    print('Frames slot counts:', batch['frames_slot_counts'].shape)\n",
    "    print('Frames value lengths:', batch['frames_value_lengths'].shape)\n",
    "    print('Frames authors:', batch['frames_authors'].shape)\n",
    "    print('Frames recently created:', batch['frames_recently_created'].shape)\n",
    "    print('Referenced frame slots:', batch['referenced_frame_slots'].shape)\n",
    "    print('Referenced frame values:', batch['referenced_frame_values'].shape)\n",
    "    print('Referenced frame slot counts:', batch['referenced_frame_slot_counts'].shape)\n",
    "    print('Referenced frame value lengths:', batch['referenced_frame_value_lengths'].shape)\n",
    "    print('DB result counts:', batch['db_result_counts'].shape)\n",
    "    print(\"TARGETS:\")\n",
    "    print('Informed value slots:', batch['user_informed_value_slots'].shape)\n",
    "    print('Informed slot states:', batch['user_informed_slot_states'].shape)\n",
    "    print('Previous active frame:', batch['previous_active_frames'].shape)\n",
    "    print('Current active frame:', batch['current_active_frames'].shape)\n",
    "    print('Agent actions:', batch['agent_actions'].shape)\n",
    "    print('Agent sub actions:', batch['agent_sub_actions'].shape)\n",
    "    \n",
    "    if i >= 0:\n",
    "        break\n",
    "    \n",
    "print((time.time() - start_at)*1000, 'ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1415,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actions: 17\n",
      "Sub actions: 139\n"
     ]
    }
   ],
   "source": [
    "print('Actions:', len(agent_actions_dictionary))\n",
    "print('Sub actions:', len(agent_sub_actions_dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.rnn import GRUCell, MultiRNNCell, ResidualWrapper, DropoutWrapper\n",
    "from tensorflow.contrib import seq2seq\n",
    "from tensorflow.python.layers.core import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training decoder\n",
      "(<tf.Tensor 'context_module/dense_2/Tanh:0' shape=(64, 600) dtype=float32>, AttentionWrapperState(cell_state=<tf.Tensor 'response_generation_module/AttentionWrapperZeroState/checked_cell_state:0' shape=(64, 600) dtype=float32>, attention=<tf.Tensor 'response_generation_module/AttentionWrapperZeroState/zeros_1:0' shape=(?, 600) dtype=float32>, time=<tf.Tensor 'response_generation_module/AttentionWrapperZeroState/zeros:0' shape=() dtype=int32>, alignments=<tf.Tensor 'response_generation_module/AttentionWrapperZeroState/zeros_2:0' shape=(?, 10) dtype=float32>, alignment_history=()))\n"
     ]
    }
   ],
   "source": [
    "def top_k_weighted(values, weights, k=2):\n",
    "    row_ids = tf.tile(tf.expand_dims(tf.range(tf.shape(values)[0]), -1), [1, k])\n",
    "    \n",
    "    selected_weights, selected_value_ids = tf.nn.top_k(weights, k=k)\n",
    "    \n",
    "    gather_indices = tf.concat([\n",
    "        tf.reshape(row_ids, [-1, 1]),\n",
    "        tf.reshape(selected_value_ids, [-1, 1])\n",
    "    ], 1)\n",
    "    \n",
    "    gathered_values = tf.gather_nd(values, gather_indices)\n",
    "    \n",
    "    return tf.multiply(\n",
    "        tf.expand_dims(selected_weights, -1),\n",
    "        tf.reshape(gathered_values, [-1, k, tf.shape(values)[-1]])\n",
    "    )\n",
    "\n",
    "class JamesBotModel():\n",
    "    \n",
    "    def __init__(self, is_training, inputs, input_lengths, previous_responses, previous_response_lengths, frames_counts, frames_slots, frames_values, frames_slot_counts, frames_value_lengths,  frames_authors, frames_recently_created, referenced_frame_slots, referenced_frame_values, referenced_frame_slot_counts, referenced_frame_value_lengths, previous_active_frame_id, database_results_count, decoder_targets=None, decoder_target_lengths=None, word_embeddings_shape=None, n_slots=None, n_actions=None, n_sub_actions=None, train=True, epoch=None, rnn_dropout_keep_prob=1.0):\n",
    "        assert word_embeddings_shape is not None\n",
    "        assert n_slots is not None\n",
    "        assert n_actions is not None\n",
    "        assert n_sub_actions is not None\n",
    "        if train:\n",
    "            assert decoder_targets is not None\n",
    "            assert decoder_target_lengths is not None\n",
    "            assert epoch is not None\n",
    "        \n",
    "        # Inputs\n",
    "        self._is_training = is_training\n",
    "        # Current/Previous Text Input\n",
    "        self._inputs = inputs\n",
    "        self._input_lengths = input_lengths\n",
    "        self._previous_responses = previous_responses\n",
    "        self._previous_response_lengths = previous_response_lengths\n",
    "        # Frames\n",
    "        self._frames_counts = frames_counts\n",
    "        self._frames_slots = frames_slots\n",
    "        self._frames_values = frames_values\n",
    "        self._frames_slot_counts = frames_slot_counts\n",
    "        self._frames_value_lengths = frames_value_lengths\n",
    "        self._frames_authors = frames_authors\n",
    "        self._frames_recently_created = frames_recently_created\n",
    "        # Referenced frame\n",
    "        self._referenced_frame_slots = referenced_frame_slots\n",
    "        self._referenced_frame_values = referenced_frame_values\n",
    "        self._referenced_frame_slot_counts = referenced_frame_slot_counts\n",
    "        self._referenced_frame_value_lengths = referenced_frame_value_lengths\n",
    "        # Indicators\n",
    "        self._previous_active_frame_id = previous_active_frame_id\n",
    "        self._database_results_count = database_results_count\n",
    "        \n",
    "        # Decoder targets (only for training)\n",
    "        self._decoder_targets = decoder_targets\n",
    "        self._decoder_target_lengths = decoder_target_lengths\n",
    "        \n",
    "        # Conf\n",
    "        self._word_embeddings_shape = word_embeddings_shape\n",
    "        self._n_slots = int(n_slots)\n",
    "        self._n_actions = int(n_actions)\n",
    "        self._n_sub_actions = int(n_sub_actions)\n",
    "        self._train = bool(train)\n",
    "        self._greedy_p = (0.5 / (1 + tf.exp(-0.2*epoch)) - 0.25)\n",
    "        self._rnn_dropout_keep_prob = rnn_dropout_keep_prob\n",
    "        \n",
    "        self._le_cell_output_size = 300\n",
    "        self._slot_embeddings_size = 300\n",
    "        self._n_slot_states = 5\n",
    "    \n",
    "    def build(self):\n",
    "        self._embeddings_module()\n",
    "        self._language_understanding_module()\n",
    "        self._frames_encoder_module()\n",
    "        self._informable_slots_module()\n",
    "        self._frame_references_module()\n",
    "        self._context_module()\n",
    "        self._dialog_policy_module()\n",
    "        self._response_generation_module()\n",
    "    \n",
    "    def embeddings_initializer(self):\n",
    "        placeholder = tf.placeholder(tf.float32)\n",
    "        init_op = self._word_embeddings.assign(placeholder)\n",
    "        return placeholder, init_op\n",
    "    \n",
    "    def _embeddings_module(self):\n",
    "        with tf.name_scope('embeddings_module'):\n",
    "            self._word_embeddings = tf.Variable(\n",
    "                tf.random_normal(self._word_embeddings_shape, -.3, .3),\n",
    "                trainable = True,\n",
    "                name = 'word_embeddings'\n",
    "            )\n",
    "            self._slot_embeddings = tf.Variable(\n",
    "                tf.random_normal([self._n_slots, self._slot_embeddings_size], -.3, .3),\n",
    "                trainable = True,\n",
    "                name = 'slot_embeddings'\n",
    "            )\n",
    "            \n",
    "            self._inputs_embedded = tf.nn.embedding_lookup(self._word_embeddings, self._inputs)\n",
    "            self._previous_responses_embedded = tf.nn.embedding_lookup(self._word_embeddings, self._previous_responses)\n",
    "            \n",
    "            self._frames_slots_embedded = tf.nn.embedding_lookup(self._slot_embeddings, self._frames_slots)\n",
    "            self._frames_values_embedded = tf.nn.embedding_lookup(self._word_embeddings, self._frames_values)\n",
    "            \n",
    "            self._referenced_frame_slots_embedded = tf.nn.embedding_lookup(self._slot_embeddings, self._referenced_frame_slots)\n",
    "            self._referenced_frame_values_embedded = tf.nn.embedding_lookup(self._word_embeddings, self._referenced_frame_values)\n",
    "        \n",
    "    def _text_encoder(self, inputs, sequence_lengths, name='text_encoder', reuse=False):\n",
    "        with tf.variable_scope(name, reuse=reuse):\n",
    "            fw_cell = GRUCell(self._le_cell_output_size, activation=tf.nn.tanh)\n",
    "            bw_cell = GRUCell(self._le_cell_output_size, activation=tf.nn.tanh)\n",
    "\n",
    "            outputs, state = tf.nn.bidirectional_dynamic_rnn(\n",
    "                fw_cell, bw_cell,\n",
    "                inputs = inputs,\n",
    "                sequence_length = sequence_lengths,\n",
    "                dtype = tf.float32,\n",
    "            )\n",
    "            \n",
    "            return tf.concat(outputs, 2, name='le_outputs'), tf.concat(state, 1, name='le_state')\n",
    "    \n",
    "    def _structs_encoder(self, slots, values, slot_counts, value_lengths, name='structs_encoder', reuse=False):\n",
    "        batch_size, n_structs, n_slots, n_tokens, _ = tf.unstack(tf.shape(values))\n",
    "\n",
    "        _, le_state = self._text_encoder(\n",
    "            tf.reshape(values, [-1, n_tokens, self._word_embeddings_shape[1]]),\n",
    "            tf.reshape(value_lengths, [-1]),\n",
    "            reuse=True\n",
    "        )\n",
    "        with tf.variable_scope(name, reuse=reuse):\n",
    "            structs_slot_value = tf.concat([\n",
    "                tf.reshape(slots, [batch_size*n_structs, n_slots, self._slot_embeddings_size]),\n",
    "                tf.reshape(le_state, [batch_size*n_structs, n_slots, 2*self._le_cell_output_size])\n",
    "            ], 2)\n",
    "            \n",
    "            _, structs_encoder_state = tf.nn.dynamic_rnn(\n",
    "                GRUCell(2*self._le_cell_output_size, activation=tf.nn.tanh),\n",
    "                inputs = structs_slot_value,\n",
    "                sequence_length = tf.reshape(slot_counts, [-1]),\n",
    "                dtype = tf.float32\n",
    "            )\n",
    "            \n",
    "            return tf.reshape(structs_encoder_state, [batch_size, n_structs, 2*self._le_cell_output_size])\n",
    "    \n",
    "    def _language_understanding_module(self):\n",
    "        with tf.name_scope('language_understanding_module'):\n",
    "            self._inputs_encoder_outputs, self._inputs_encoder_state = self._text_encoder(\n",
    "                self._inputs_embedded,\n",
    "                self._input_lengths\n",
    "            )\n",
    "            \n",
    "            self._previous_responses_encoder_outputs, self._previous_responses_encoder_state = self._text_encoder(\n",
    "                self._previous_responses_embedded,\n",
    "                self._previous_response_lengths,\n",
    "                reuse=True\n",
    "            )\n",
    "    \n",
    "    def _frames_encoder_module(self):\n",
    "        with tf.name_scope('frames_encoder_module'):\n",
    "            # Input frames\n",
    "            encoder_output = self._structs_encoder(\n",
    "                self._frames_slots_embedded,\n",
    "                self._frames_values_embedded,\n",
    "                self._frames_slot_counts,\n",
    "                self._frames_value_lengths\n",
    "            )\n",
    "            mask = tf.sequence_mask(self._frames_counts, tf.reduce_max(self._frames_counts), dtype=tf.float32)\n",
    "                \n",
    "            self._frames_encoded = tf.multiply(\n",
    "                tf.expand_dims(mask, -1),\n",
    "                encoder_output\n",
    "            )\n",
    "            \n",
    "            # Referenced frame\n",
    "            referenced_frame_encoder_output = self._structs_encoder(\n",
    "                tf.expand_dims(self._referenced_frame_slots_embedded, 1),\n",
    "                tf.expand_dims(self._referenced_frame_values_embedded, 1),\n",
    "                self._referenced_frame_slot_counts,\n",
    "                self._referenced_frame_value_lengths,\n",
    "                reuse = True\n",
    "            )\n",
    "            self._referenced_frame_encoded = tf.squeeze(referenced_frame_encoder_output, 1)\n",
    "\n",
    "            # Referenced frame slot indicators [batch_size,n_slots]\n",
    "            self._referenced_frame_slot_indicators = tf.multiply(\n",
    "                tf.reduce_sum(tf.one_hot(self._referenced_frame_slots, self._n_slots), 1),\n",
    "                tf.tile(1 - tf.sequence_mask([1], self._n_slots, dtype=tf.float32), [tf.shape(self._referenced_frame_slots)[0], 1])\n",
    "            )\n",
    "    \n",
    "    def _informable_slots_module(self):\n",
    "        with tf.variable_scope('informable_slots_module'):\n",
    "            # Informable slots\n",
    "            e_inputs = tf.layers.dense(\n",
    "                self._inputs_encoder_outputs,\n",
    "                2*self._le_cell_output_size,\n",
    "                activation=tf.nn.tanh,\n",
    "                name='weights_projection'\n",
    "            )\n",
    "            e_previous_responses = tf.layers.dense(\n",
    "                self._previous_responses_encoder_outputs,\n",
    "                2*self._le_cell_output_size,\n",
    "                activation=tf.nn.tanh,\n",
    "                name='weights_projection',\n",
    "                reuse=True\n",
    "            )\n",
    "            \n",
    "            e = tf.matmul(e_inputs, e_previous_responses, transpose_b=True, name='e')\n",
    "            beta = tf.matmul(tf.nn.softmax(e), self._previous_responses_encoder_outputs)\n",
    "            \n",
    "            inputs_compared = tf.layers.dense(\n",
    "                tf.concat([self._inputs_encoder_outputs, beta], 2),\n",
    "                2*self._le_cell_output_size,\n",
    "                activation=tf.nn.tanh,\n",
    "                name='comparison'\n",
    "            )\n",
    "            \n",
    "            self._informable_slots_logits = tf.layers.dense(\n",
    "                inputs_compared,\n",
    "                self._n_slots,\n",
    "            )\n",
    "            self.informable_slots_p = tf.nn.softmax(self._informable_slots_logits)\n",
    "            self.informable_slots_indicators = tf.reduce_sum(self.informable_slots_p, 1)\n",
    "            \n",
    "            # Slot states\n",
    "            slot_states_input = tf.concat([\n",
    "                self._previous_responses_encoder_state,\n",
    "                self._inputs_encoder_state\n",
    "            ], 1)\n",
    "            \n",
    "            slot_states_output = tf.layers.dense(slot_states_input, self._n_slots*self._n_slot_states)\n",
    "            self._informable_slot_states_logits = tf.reshape(slot_states_output, [tf.shape(self._inputs)[0], self._n_slots, self._n_slot_states])\n",
    "            self.informable_slot_states_p = tf.nn.sigmoid(self._informable_slot_states_logits)\n",
    "    \n",
    "    def _frame_references_module(self):\n",
    "        with tf.name_scope('frame_references_module'):\n",
    "            batch_size, n_frames, _ = tf.unstack(tf.shape(self._frames_encoded))\n",
    "            \n",
    "            self._frames_authors_onehot = tf.one_hot(self._frames_authors, 2)\n",
    "            self._frames_recently_created_onehot = tf.reduce_sum(tf.one_hot(self._frames_recently_created, n_frames), 1)\n",
    "            self._previous_active_frame_onehot = tf.one_hot(self._previous_active_frame_id, n_frames)\n",
    "            \n",
    "            frames_with_indicators = tf.concat([\n",
    "                self._frames_encoded, # [batch_size,n_frames,2*cell_size]\n",
    "                self._frames_authors_onehot, # [batch_size,n_frames,2]\n",
    "                tf.expand_dims(self._frames_recently_created_onehot, -1), # [batch_size,n_frames,1]\n",
    "                tf.expand_dims(self._previous_active_frame_onehot, -1) # [batch_size,n_frames,1]\n",
    "            ], 2)\n",
    "            \n",
    "            self._available_frames = tf.concat([\n",
    "                frames_with_indicators,\n",
    "                tf.zeros([batch_size, 1, 2*self._le_cell_output_size+4])\n",
    "            ], 1, name='available_frames')\n",
    "            \n",
    "            # Project frames\n",
    "            frames_sim_proj = tf.layers.dense(\n",
    "                tf.layers.dropout(\n",
    "                    self._available_frames,\n",
    "                    rate = 0.3,\n",
    "                    training = self._is_training\n",
    "                ),\n",
    "                int(self._le_cell_output_size/2),\n",
    "                activation=tf.nn.tanh\n",
    "            )\n",
    "            \n",
    "            # Project inputs\n",
    "            inputs_sim_proj = tf.layers.dense(\n",
    "                tf.layers.dropout(\n",
    "                    tf.concat([\n",
    "                        self._inputs_encoder_state,\n",
    "                        tf.reshape(self.informable_slot_states_p, [batch_size, self._n_slots*self._n_slot_states])\n",
    "                    ], 1),\n",
    "                    rate = 0.3,\n",
    "                    training = self._is_training\n",
    "                ),\n",
    "                int(self._le_cell_output_size/2),\n",
    "                activation=tf.nn.tanh\n",
    "            )\n",
    "            \n",
    "            # Compute input-frame similarity\n",
    "            sim = tf.matmul(\n",
    "                tf.expand_dims(inputs_sim_proj, 1),\n",
    "                frames_sim_proj,\n",
    "                transpose_b = True\n",
    "            )\n",
    "            \n",
    "            # Mask padded values\n",
    "            self._frame_references_logits = tf.multiply(\n",
    "                tf.sequence_mask(self._frames_counts+1, tf.reduce_max(self._frames_counts)+1, dtype=tf.float32),\n",
    "                tf.squeeze(sim, 1)\n",
    "            )\n",
    "            self.frame_references_p = tf.nn.softmax(self._frame_references_logits)\n",
    "    \n",
    "    def _context_module(self):\n",
    "        with tf.variable_scope('context_module'):\n",
    "            batch_size, n_frames, _ = tf.unstack(tf.shape(self._available_frames))\n",
    "            self._database_results_count_onehot = tf.one_hot(tf.clip_by_value(self._database_results_count, 0, 5), 6)\n",
    "            \n",
    "            context_nn_input = tf.concat([\n",
    "                self._previous_responses_encoder_state,\n",
    "                self._inputs_encoder_state,\n",
    "                self._referenced_frame_encoded,\n",
    "                self._referenced_frame_slot_indicators,\n",
    "                self._database_results_count_onehot\n",
    "            ], 1)\n",
    "            \n",
    "            context_L1 = tf.layers.dense(\n",
    "                tf.layers.dropout(context_nn_input, rate=0.3, training=self._is_training),\n",
    "                2*self._le_cell_output_size,\n",
    "                activation=tf.nn.tanh\n",
    "            )\n",
    "            \n",
    "            self._context = tf.layers.dense(\n",
    "                tf.layers.dropout(context_L1, rate=0.3, training=self._is_training),\n",
    "                2*self._le_cell_output_size,\n",
    "                activation=tf.nn.tanh\n",
    "            )\n",
    "            \n",
    "    def _dialog_policy_module(self):\n",
    "        with tf.name_scope('dialog_policy_module'):\n",
    "            self._actions_logits = tf.layers.dense(self._context, self._n_actions)\n",
    "            self.actions_p = tf.nn.sigmoid(self._actions_logits)\n",
    "            \n",
    "            self._sub_actions_logits = tf.layers.dense(self._context, self._n_sub_actions)\n",
    "            self.sub_actions_p = tf.nn.sigmoid(self._sub_actions_logits)\n",
    "        \n",
    "    def _prepare_training_decoder(self):\n",
    "        batch_size, _ = tf.unstack(tf.shape(self._decoder_targets))\n",
    "        pad = tf.zeros([batch_size, 1], dtype=tf.int64)\n",
    "        \n",
    "        self._decoder_inputs = tf.concat([pad, self._decoder_targets], 1)\n",
    "        self._decoder_inputs_embedded = tf.nn.embedding_lookup(self._word_embeddings, self._decoder_inputs)\n",
    "        self._decoder_targets_padded = tf.concat([self._decoder_targets, pad], 1)\n",
    "            \n",
    "    def _response_generation_module(self):\n",
    "        with tf.variable_scope('response_generation_module'):\n",
    "            batch_size, n_tokens = tf.unstack(tf.shape(self._inputs))\n",
    "            if self._train:\n",
    "                print('Training decoder')\n",
    "                self._prepare_training_decoder()\n",
    "\n",
    "                helper = seq2seq.ScheduledEmbeddingTrainingHelper(\n",
    "                    inputs = self._decoder_inputs_embedded,\n",
    "                    sequence_length = self._decoder_target_lengths + 1,\n",
    "                    embedding = self._word_embeddings,\n",
    "                    sampling_probability = self._greedy_p,\n",
    "                )\n",
    "            else:\n",
    "                print('Inference decoder')\n",
    "                helper = seq2seq.GreedyEmbeddingHelper(\n",
    "                    embedding = self._word_embeddings,\n",
    "                    start_tokens = tf.tile([0], [batch_size]),\n",
    "                    end_token = 1\n",
    "                )\n",
    "                \n",
    "            decoder_cell, initial_state = self._decoder_cell()\n",
    "            \n",
    "            print(initial_state)\n",
    "            \n",
    "            decoder = seq2seq.BasicDecoder(\n",
    "                cell = decoder_cell,\n",
    "                helper = helper,\n",
    "                initial_state = initial_state,\n",
    "                output_layer=Dense(self._word_embeddings_shape[0])\n",
    "            )\n",
    "            decoder_outputs, _, _ = seq2seq.dynamic_decode(decoder, impute_finished=True)\n",
    "            \n",
    "            self._decoder_logits = decoder_outputs.rnn_output\n",
    "            self.decoder_embedding_ids = tf.argmax(self._decoder_logits, -1)\n",
    "    \n",
    "    def _decoder_cell(self):\n",
    "        def _base_cell():\n",
    "            return DropoutWrapper(\n",
    "                GRUCell(2*self._le_cell_output_size),\n",
    "                output_keep_prob=self._rnn_dropout_keep_prob\n",
    "            )\n",
    "        \n",
    "        batch_size, n_tokens = tf.unstack(tf.shape(self._inputs))\n",
    "        \n",
    "        attention_memory = tf.concat([\n",
    "            self._inputs_encoder_outputs,\n",
    "            tf.tile(tf.expand_dims(self._referenced_frame_encoded, 1), [1,n_tokens,1]),\n",
    "            tf.tile(tf.expand_dims(self._referenced_frame_slot_indicators, 1), [1,n_tokens,1]),\n",
    "            tf.tile(tf.expand_dims(self._database_results_count_onehot, 1), [1,n_tokens,1])\n",
    "        ], 2)\n",
    "\n",
    "        attention_mechanism = seq2seq.BahdanauAttention(\n",
    "            num_units = 2*self._le_cell_output_size,\n",
    "            memory = attention_memory,\n",
    "            memory_sequence_length = self._input_lengths\n",
    "        )\n",
    "\n",
    "        attentive_cell = seq2seq.AttentionWrapper(\n",
    "            cell = _base_cell(),\n",
    "            attention_mechanism = attention_mechanism,\n",
    "            attention_layer_size = 2*self._le_cell_output_size,\n",
    "            initial_cell_state = self._context\n",
    "        )\n",
    "        \n",
    "        initial_state = tuple([\n",
    "            self._context,\n",
    "            attentive_cell.zero_state(batch_size, dtype=tf.float32),\n",
    "        ])\n",
    "        \n",
    "        return MultiRNNCell([\n",
    "            _base_cell(),\n",
    "            attentive_cell,\n",
    "        ], state_is_tuple=True), initial_state\n",
    "           \n",
    "    def losses(self, informable_slots_targets, informable_slot_states_targets, frame_references_targets, actions_targets, sub_actions_targets):\n",
    "        # Informable slots\n",
    "        informable_slots_stepwise_ce = tf.nn.softmax_cross_entropy_with_logits(\n",
    "            labels = tf.one_hot(informable_slots_targets, self._n_slots),\n",
    "            logits = self._informable_slots_logits\n",
    "        )\n",
    "        informable_slots_loss = tf.reduce_mean(informable_slots_stepwise_ce)\n",
    "        informable_slots_accuracy = tf.reduce_mean(tf.cast(tf.equal(informable_slots_targets, tf.argmax(self.informable_slots_p, -1)), tf.float32))\n",
    "        \n",
    "        informable_slot_statewise_ce = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            labels = tf.one_hot(informable_slot_states_targets, self._n_slot_states),\n",
    "            logits = self._informable_slot_states_logits\n",
    "        )\n",
    "        informable_slot_states_loss = tf.reduce_mean(informable_slot_statewise_ce)\n",
    "        informable_slot_states_accuracy = tf.reduce_mean(tf.cast(tf.equal(informable_slot_states_targets, tf.argmax(self.informable_slot_states_p, -1)), tf.float32))\n",
    "        \n",
    "        # Frames\n",
    "        frame_references_framewise_ce = tf.nn.softmax_cross_entropy_with_logits(\n",
    "            labels = tf.one_hot(frame_references_targets, (tf.shape(self._frames_slots)[1]+1)),\n",
    "            logits = self._frame_references_logits\n",
    "        )\n",
    "        frame_references_loss = tf.reduce_mean(frame_references_framewise_ce)\n",
    "        frame_references_accuracy = tf.reduce_mean(tf.cast(tf.equal(frame_references_targets, tf.argmax(self.frame_references_p, -1)), tf.float32))\n",
    "        \n",
    "        # Actions\n",
    "        actions_targets_encoded = tf.reduce_sum(tf.one_hot(actions_targets, self._n_actions), 1)\n",
    "        actions_ce = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            labels = actions_targets_encoded,\n",
    "            logits = self._actions_logits\n",
    "        )\n",
    "        actions_loss = tf.reduce_mean(actions_ce)\n",
    "        actions_accuracy = tf.reduce_mean(tf.cast(tf.equal(actions_targets_encoded, tf.round(self.actions_p)), tf.float32))\n",
    "        \n",
    "        sub_actions_targets_encoded = tf.reduce_sum(tf.one_hot(sub_actions_targets, self._n_sub_actions), 1)\n",
    "        sub_actions_ce = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            labels = sub_actions_targets_encoded,\n",
    "            logits = self._sub_actions_logits\n",
    "        )\n",
    "        sub_actions_loss = tf.reduce_mean(sub_actions_ce)\n",
    "        sub_actions_accuracy = tf.reduce_mean(tf.cast(tf.equal(sub_actions_targets_encoded, tf.round(self.sub_actions_p)), tf.float32))\n",
    "        \n",
    "        # Decoder\n",
    "        decoder_stepwise_ce = tf.nn.softmax_cross_entropy_with_logits(\n",
    "            labels = tf.one_hot(self._decoder_targets_padded, self._word_embeddings_shape[0]),\n",
    "            logits = self._decoder_logits\n",
    "        )\n",
    "        decoder_loss = tf.reduce_mean(decoder_stepwise_ce)\n",
    "        decoder_accuracy = tf.reduce_mean(tf.cast(tf.equal(self._decoder_targets_padded, self.decoder_embedding_ids), tf.float32))\n",
    "        \n",
    "        total_loss = tf.reduce_sum([\n",
    "            informable_slots_loss,\n",
    "            informable_slot_states_loss,\n",
    "            frame_references_loss,\n",
    "            actions_loss,\n",
    "            sub_actions_loss,\n",
    "            decoder_loss,\n",
    "        ])\n",
    "\n",
    "        tf.summary.histogram('actions_targets_encoded', actions_targets_encoded)\n",
    "        tf.summary.histogram('sub_actions_targets_encoded', sub_actions_targets_encoded)\n",
    "        tf.summary.scalar('total_loss', total_loss)\n",
    "        tf.summary.scalar('informable_slots_loss', informable_slots_loss)\n",
    "        tf.summary.scalar('informable_slots_accuracy', informable_slots_accuracy)\n",
    "        tf.summary.scalar('informable_slot_states_loss', informable_slot_states_loss)\n",
    "        tf.summary.scalar('informable_slot_states_accuracy', informable_slot_states_accuracy)\n",
    "        tf.summary.scalar('frame_references_loss', frame_references_loss)\n",
    "        tf.summary.scalar('frame_references_accuracy', frame_references_accuracy)\n",
    "        tf.summary.scalar('actions_loss', actions_loss)\n",
    "        tf.summary.scalar('actions_accuracy', actions_accuracy)\n",
    "        tf.summary.scalar('sub_actions_loss', sub_actions_loss)\n",
    "        tf.summary.scalar('sub_actions_accuracy', sub_actions_accuracy)\n",
    "        tf.summary.scalar('decoder_loss', decoder_loss)\n",
    "        tf.summary.scalar('decoder_accuracy', decoder_accuracy)\n",
    "        tf.summary.scalar('decoder_sampling_p', self._greedy_p)\n",
    "        \n",
    "        return total_loss\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    training_ph = tf.placeholder(tf.bool)\n",
    "    # Text\n",
    "    inputs_ph = tf.placeholder(tf.int64, [64, 10])\n",
    "    input_lengths_ph = tf.placeholder(tf.int32, [64])\n",
    "    previous_responses_ph = tf.placeholder(tf.int64, [64,7])\n",
    "    previous_response_lengths_ph = tf.placeholder(tf.int32, [64])\n",
    "    # Frames\n",
    "    frames_counts_ph = tf.placeholder(tf.int32, [64])\n",
    "    frames_slots_ph = tf.placeholder(tf.int64, [64,3,5])\n",
    "    frames_values_ph = tf.placeholder(tf.int64, [64,3,5,10])\n",
    "    frames_slot_counts_ph = tf.placeholder(tf.int64, [64,3])\n",
    "    frames_value_lengths_ph = tf.placeholder(tf.int64, [64,3,5])\n",
    "    frames_authors_ph = tf.placeholder(tf.int32, [64,3])\n",
    "    frames_recently_created_ph = tf.placeholder(tf.int32, [64,2])\n",
    "    # Referenced frame\n",
    "    referenced_frame_slots_ph = tf.placeholder(tf.int64, [64,7])\n",
    "    referenced_frame_values_ph = tf.placeholder(tf.int64, [64,7,3])\n",
    "    referenced_frame_slot_counts_ph = tf.placeholder(tf.int64, [64])\n",
    "    referenced_frame_value_lengths_ph = tf.placeholder(tf.int64, [64,7])\n",
    "    # Indicators\n",
    "    previous_active_frame_ph = tf.placeholder(tf.int32, [64])\n",
    "    database_results_count_ph = tf.placeholder(tf.int32, [64])\n",
    "    \n",
    "    decoder_targets_ph = tf.placeholder(tf.int64, [64, 12])\n",
    "    decoder_target_lengths_ph = tf.placeholder(tf.int32, [64])\n",
    "    \n",
    "    informable_slots_targets_ph = tf.placeholder(tf.int64, [64,10])\n",
    "    informable_slots_states_targets_ph = tf.placeholder(tf.int64, [64,12])\n",
    "    frame_references_targets_ph = tf.placeholder(tf.int64, [64])\n",
    "    \n",
    "    actions_targets_ph = tf.placeholder(tf.int64, [64, 5])\n",
    "    sub_actions_targets_ph = tf.placeholder(tf.int64, [64, 8])\n",
    "    \n",
    "    epoch_ph = tf.placeholder(tf.float32, [])\n",
    "    rnn_dropout_keep_prob_ph = tf.placeholder(tf.float32)\n",
    "    \n",
    "    model = JamesBotModel(\n",
    "        training_ph,\n",
    "        inputs_ph, input_lengths_ph,\n",
    "        previous_responses_ph, previous_response_lengths_ph,\n",
    "        frames_counts_ph, frames_slots_ph, frames_values_ph, frames_slot_counts_ph, frames_value_lengths_ph, frames_authors_ph, frames_recently_created_ph,\n",
    "        referenced_frame_slots_ph, referenced_frame_values_ph, referenced_frame_slot_counts_ph, referenced_frame_value_lengths_ph,\n",
    "        previous_active_frame_ph, database_results_count_ph,\n",
    "        decoder_targets=decoder_targets_ph, decoder_target_lengths=decoder_target_lengths_ph,\n",
    "        word_embeddings_shape=[9600,300], n_slots=12, n_actions=9, n_sub_actions=21,\n",
    "        epoch=epoch_ph, rnn_dropout_keep_prob=rnn_dropout_keep_prob_ph\n",
    "    )\n",
    "    model.build()\n",
    "    \n",
    "    model.losses(informable_slots_targets_ph, informable_slots_states_targets_ph, frame_references_targets_ph, actions_targets_ph, sub_actions_targets_ph) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1431,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1532,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training decoder\n",
      "embeddings_module/word_embeddings:0\n",
      "embeddings_module/slot_embeddings:0\n",
      "text_encoder/bidirectional_rnn/fw/gru_cell/gates/kernel:0\n",
      "text_encoder/bidirectional_rnn/fw/gru_cell/gates/bias:0\n",
      "text_encoder/bidirectional_rnn/fw/gru_cell/candidate/kernel:0\n",
      "text_encoder/bidirectional_rnn/fw/gru_cell/candidate/bias:0\n",
      "text_encoder/bidirectional_rnn/bw/gru_cell/gates/kernel:0\n",
      "text_encoder/bidirectional_rnn/bw/gru_cell/gates/bias:0\n",
      "text_encoder/bidirectional_rnn/bw/gru_cell/candidate/kernel:0\n",
      "text_encoder/bidirectional_rnn/bw/gru_cell/candidate/bias:0\n",
      "structs_encoder/rnn/gru_cell/gates/kernel:0\n",
      "structs_encoder/rnn/gru_cell/gates/bias:0\n",
      "structs_encoder/rnn/gru_cell/candidate/kernel:0\n",
      "structs_encoder/rnn/gru_cell/candidate/bias:0\n",
      "informable_slots_module/weights_projection/kernel:0\n",
      "informable_slots_module/weights_projection/bias:0\n",
      "informable_slots_module/comparison/kernel:0\n",
      "informable_slots_module/comparison/bias:0\n",
      "informable_slots_module/dense/kernel:0\n",
      "informable_slots_module/dense/bias:0\n",
      "informable_slots_module/dense_1/kernel:0\n",
      "informable_slots_module/dense_1/bias:0\n",
      "dense/kernel:0\n",
      "dense/bias:0\n",
      "dense_1/kernel:0\n",
      "dense_1/bias:0\n",
      "context_module/dense/kernel:0\n",
      "context_module/dense/bias:0\n",
      "context_module/dense_1/kernel:0\n",
      "context_module/dense_1/bias:0\n",
      "dense_2/kernel:0\n",
      "dense_2/bias:0\n",
      "dense_3/kernel:0\n",
      "dense_3/bias:0\n",
      "response_generation_module/memory_layer/kernel:0\n",
      "response_generation_module/decoder/multi_rnn_cell/cell_0/gru_cell/gates/kernel:0\n",
      "response_generation_module/decoder/multi_rnn_cell/cell_0/gru_cell/gates/bias:0\n",
      "response_generation_module/decoder/multi_rnn_cell/cell_0/gru_cell/candidate/kernel:0\n",
      "response_generation_module/decoder/multi_rnn_cell/cell_0/gru_cell/candidate/bias:0\n",
      "response_generation_module/decoder/multi_rnn_cell/cell_1/attention_wrapper/gru_cell/gates/kernel:0\n",
      "response_generation_module/decoder/multi_rnn_cell/cell_1/attention_wrapper/gru_cell/gates/bias:0\n",
      "response_generation_module/decoder/multi_rnn_cell/cell_1/attention_wrapper/gru_cell/candidate/kernel:0\n",
      "response_generation_module/decoder/multi_rnn_cell/cell_1/attention_wrapper/gru_cell/candidate/bias:0\n",
      "response_generation_module/decoder/multi_rnn_cell/cell_1/attention_wrapper/bahdanau_attention/query_layer/kernel:0\n",
      "response_generation_module/decoder/multi_rnn_cell/cell_1/attention_wrapper/bahdanau_attention/attention_v:0\n",
      "response_generation_module/decoder/multi_rnn_cell/cell_1/attention_wrapper/attention_layer/kernel:0\n",
      "response_generation_module/decoder/dense/kernel:0\n",
      "response_generation_module/decoder/dense/bias:0\n",
      "Trainable parameters: 18686705\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    is_training_ph = tf.placeholder(tf.bool)\n",
    "    # Text\n",
    "    inputs_ph = tf.placeholder(tf.int64, [None, None])\n",
    "    input_lengths_ph = tf.placeholder(tf.int32, [None])\n",
    "    previous_responses_ph = tf.placeholder(tf.int64, [None, None])\n",
    "    previous_response_lengths_ph = tf.placeholder(tf.int32, [None])\n",
    "    # Frames\n",
    "    frames_counts_ph = tf.placeholder(tf.int32, [None])\n",
    "    frames_slots_ph = tf.placeholder(tf.int64, [None, None, None])\n",
    "    frames_values_ph = tf.placeholder(tf.int64, [None, None, None, None])\n",
    "    frames_slot_counts_ph = tf.placeholder(tf.int64, [None, None])\n",
    "    frames_value_lengths_ph = tf.placeholder(tf.int64, [None, None, None])\n",
    "    frames_authors_ph = tf.placeholder(tf.int32, [None, None])\n",
    "    frames_recently_created_ph = tf.placeholder(tf.int32, [None, None])\n",
    "    # Referenced frame\n",
    "    referenced_frame_slots_ph = tf.placeholder(tf.int64, [None, None])\n",
    "    referenced_frame_values_ph = tf.placeholder(tf.int64, [None, None, None])\n",
    "    referenced_frame_slot_counts_ph = tf.placeholder(tf.int64, [None])\n",
    "    referenced_frame_value_lengths_ph = tf.placeholder(tf.int64, [None, None])\n",
    "    # Indicators\n",
    "    previous_active_frame_ph = tf.placeholder(tf.int32, [None])\n",
    "    database_results_count_ph = tf.placeholder(tf.int32, [None])\n",
    "    \n",
    "    decoder_targets_ph = tf.placeholder(tf.int64, [None, None])\n",
    "    decoder_target_lengths_ph = tf.placeholder(tf.int32, [None])\n",
    "    \n",
    "    informable_slots_targets_ph = tf.placeholder(tf.int64, [None, None])\n",
    "    informable_slot_states_targets_ph = tf.placeholder(tf.int64, [None, None])\n",
    "    frame_references_targets_ph = tf.placeholder(tf.int64, [None])\n",
    "    \n",
    "    actions_targets_ph = tf.placeholder(tf.int64, [None, None])\n",
    "    sub_actions_targets_ph = tf.placeholder(tf.int64, [None, None])\n",
    "    \n",
    "    epoch_ph = tf.placeholder(tf.float32, [])\n",
    "    rnn_dropout_keep_prob_ph = tf.placeholder(tf.float32)\n",
    "    \n",
    "    model = JamesBotModel(\n",
    "        is_training_ph,\n",
    "        inputs_ph, input_lengths_ph,\n",
    "        previous_responses_ph, previous_response_lengths_ph,\n",
    "        frames_counts_ph, frames_slots_ph, frames_values_ph, frames_slot_counts_ph, frames_value_lengths_ph, frames_authors_ph, frames_recently_created_ph,\n",
    "        referenced_frame_slots_ph, referenced_frame_values_ph, referenced_frame_slot_counts_ph, referenced_frame_value_lengths_ph,\n",
    "        previous_active_frame_ph, database_results_count_ph,\n",
    "        decoder_targets=decoder_targets_ph, decoder_target_lengths=decoder_target_lengths_ph,\n",
    "        word_embeddings_shape=embeddings.shape, n_slots=len(slots_dictionary),\n",
    "        n_actions=len(agent_actions_dictionary), n_sub_actions=len(agent_sub_actions_dictionary),\n",
    "        epoch=epoch_ph, train=True, rnn_dropout_keep_prob=rnn_dropout_keep_prob_ph\n",
    "    )\n",
    "    model.build()\n",
    "    embeddings_ph, embeddings_init_op = model.embeddings_initializer()\n",
    "    \n",
    "    total_loss = model.losses(informable_slots_targets_ph, informable_slot_states_targets_ph, frame_references_targets_ph, actions_targets_ph, sub_actions_targets_ph)\n",
    "    \n",
    "    train_op = tf.train.AdamOptimizer().minimize(total_loss)\n",
    "    saver = tf.train.Saver(max_to_keep=None)\n",
    "    \n",
    "    for var in tf.trainable_variables():\n",
    "        print(var.name)\n",
    "    \n",
    "    print('Trainable parameters:', np.sum([np.prod(var.get_shape().as_list()) for var in tf.trainable_variables()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1467,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 1467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(slots_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1524,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling p: 0.0\n",
      "0 Total loss: 15.4035\n",
      "Sampling p: 0.024917\n",
      "1 Total loss: 13.1524\n",
      "Sampling p: 0.0493438\n",
      "2 Total loss: 12.0684\n",
      "Sampling p: 0.0728281\n",
      "3 Total loss: 11.0698\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1524-25a9a3b9e8e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m         }\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_greedy_p\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Sampling p:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m#         if i % 5 == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marekgalovic/.virtualenvs/data/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marekgalovic/.virtualenvs/data/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marekgalovic/.virtualenvs/data/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marekgalovic/.virtualenvs/data/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marekgalovic/.virtualenvs/data/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# sess = tf.InteractiveSession(graph=graph)\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(embeddings_init_op, feed_dict={embeddings_ph: embeddings})\n",
    "\n",
    "    for i, batch in enumerate(samples_iterator(turns_train)):\n",
    "        \n",
    "        fd = {\n",
    "            is_training_ph: True,\n",
    "            inputs_ph: batch['user_inputs'],\n",
    "            input_lengths_ph: batch['user_input_lengths'],\n",
    "            previous_responses_ph: batch['previous_responses'],\n",
    "            previous_response_lengths_ph: batch['previous_response_lengths'],\n",
    "            # Frames\n",
    "            frames_counts_ph: batch['frames_counts'],\n",
    "            frames_slots_ph: batch['frames_slots'],\n",
    "            frames_values_ph: batch['frames_values'],\n",
    "            frames_slot_counts_ph: batch['frames_slot_counts'],\n",
    "            frames_value_lengths_ph: batch['frames_value_lengths'],\n",
    "            frames_authors_ph: batch['frames_authors'],\n",
    "            frames_recently_created_ph: batch['frames_recently_created'],\n",
    "            # Referenced frame\n",
    "            referenced_frame_slots_ph: batch['referenced_frame_slots'],\n",
    "            referenced_frame_values_ph: batch['referenced_frame_values'],\n",
    "            referenced_frame_slot_counts_ph: batch['referenced_frame_slot_counts'],\n",
    "            referenced_frame_value_lengths_ph: batch['referenced_frame_value_lengths'],\n",
    "            # Indicators\n",
    "            previous_active_frame_ph: batch['previous_active_frames'],\n",
    "            database_results_count_ph: batch['db_result_counts'],\n",
    "            # Targets\n",
    "            informable_slots_targets_ph: batch['user_informed_value_slots'],\n",
    "            informable_slot_states_targets_ph: batch['user_informed_slot_states'],\n",
    "            frame_references_targets_ph: batch['current_active_frames'],\n",
    "            decoder_targets_ph: batch['next_responses'],\n",
    "            decoder_target_lengths_ph: batch['next_response_lengths'],\n",
    "            actions_targets_ph: batch['agent_actions'],\n",
    "            sub_actions_targets_ph: batch['agent_sub_actions'],\n",
    "            # Conf\n",
    "            epoch_ph: float(i),\n",
    "            rnn_dropout_keep_prob_ph: 0.7\n",
    "        }\n",
    "\n",
    "        _, loss_val, sampling_p = sess.run([train_op, total_loss, model._greedy_p], feed_dict = fd)\n",
    "        print('Sampling p:', sampling_p)\n",
    "#         if i % 5 == 0:\n",
    "        print(i, 'Total loss:', loss_val)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1304,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1332,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,\n",
       "         1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 1332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_slots = 51\n",
    "\n",
    "present_slots = tf.constant([\n",
    "    [1,17,4,45,0,0],\n",
    "    [1,45,9,21,11,13]\n",
    "], tf.int32)\n",
    "\n",
    "slot_indicators = tf.multiply(\n",
    "    tf.reduce_sum(tf.one_hot(present_slots, n_slots), 1),\n",
    "    tf.tile(1 - tf.sequence_mask([1], 51, dtype=tf.float32), [2, 1])\n",
    ")\n",
    "\n",
    "sess.run(slot_indicators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1092,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../checkpoints/gcloud_responses_9/checkpoints.ckpt-23\n",
      "Frames:\n",
      "{'or_city': 'UNK', 'dst_city': 'UNK'}\n",
      "Agent response: _\n",
      "User input: Hey! I would like to book a flight to Frankfurt\n",
      "Agent response: okay , i can help you with that ! where are you coming from ? <EOS>\n",
      "Previous frame\n",
      "\n",
      "[[ 0.48071796  0.48071796  0.03856414]]\n",
      "{'dst_city': 'frankfurt'}\n"
     ]
    }
   ],
   "source": [
    "def embed_sentence(sentence):\n",
    "    return np.array([glove_dictionary.get(token, 2) for token in nltk.word_tokenize(str(sentence).lower())])\n",
    "\n",
    "def embed_frame(frame):\n",
    "    embedded = {}\n",
    "    for (key, value) in frame.items():\n",
    "        embedded[slots_dictionary.get(key)] = embed_sentence(value)\n",
    "    return embedded\n",
    "        \n",
    "\n",
    "def parse_slots(sentence, slot_ids):\n",
    "    tokens = nltk.word_tokenize(str(sentence).lower())\n",
    "    assert len(tokens) == len(slot_ids)\n",
    "    \n",
    "    resolved = []\n",
    "    for idx, slot_id in enumerate(slot_ids):\n",
    "        if slot_id > 0:\n",
    "            if len(resolved) == 0:\n",
    "                resolved.append([slot_id, tokens[idx]])\n",
    "            else:\n",
    "                if resolved[-1][0] == slot_id:\n",
    "                    resolved[-1].append(tokens[idx])\n",
    "                else:\n",
    "                    resolved.append([slot_id, tokens[idx]])\n",
    "    \n",
    "    return {slots_index.get(val[0]): ' '.join(val[1:]) for val in resolved}\n",
    "\n",
    "frames = [\n",
    "    {'or_city': 'UNK', 'dst_city': 'UNK'},\n",
    "#     {'or_city': 'Frankfurt', 'dst_city': 'Toronto', 'price': 2432.32},\n",
    "#     {'or_city': 'Frankfurt', 'dst_city': 'Caprica'},\n",
    "#     {'or_city': 'Frankfurt', 'dst_city': 'Vancouver'}\n",
    "]\n",
    "embedded_frames = [embed_frame(frame) for frame in frames]\n",
    "\n",
    "frames_slots, frames_values, frames_slot_counts, frames_value_lengths = pad_array_of_complex(embedded_frames, 3, 1)\n",
    "\n",
    "previous_active_frame_id = 0\n",
    "previous_response = '_'\n",
    "current_input = 'Hey! I would like to book a flight to Frankfurt'\n",
    "\n",
    "previous_response_embedding_ids = embed_sentence(previous_response)\n",
    "current_input_embedding_ids = embed_sentence(current_input)\n",
    "\n",
    "# frames_slot_counts, frames_value_lengths, frames_slots, frames_values = pad_frames([frames_embedded], len(frames_embedded))\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    saver.restore(sess, '../checkpoints/gcloud_responses_20/checkpoints.ckpt-9')\n",
    "    fd = {\n",
    "        is_training_ph: False,\n",
    "        inputs_ph: [current_input_embedding_ids],\n",
    "        input_lengths_ph: [len(current_input_embedding_ids)],\n",
    "        previous_responses_ph: [previous_response_embedding_ids],\n",
    "        previous_response_lengths_ph: [len(previous_response_embedding_ids)],\n",
    "        frames_slots_ph: [frames_slots],\n",
    "        frames_values_ph: [frames_values],\n",
    "        frames_slot_counts_ph: [frames_slot_counts],\n",
    "        frames_value_lengths_ph: [frames_value_lengths],\n",
    "        previous_active_frame_ph: [previous_active_frame_id],\n",
    "        database_results_count_ph: [1]\n",
    "    }\n",
    "    result, frame_references, decoded_ids = sess.run([model.informable_slots_p, model.frame_references_p, model.decoder_embedding_ids], feed_dict = fd)\n",
    "    \n",
    "    print('Frames:')\n",
    "    for frame in frames:\n",
    "        print(frame)\n",
    "    \n",
    "    print('Agent response:', previous_response)\n",
    "    print('User input:', current_input)\n",
    "    print('Agent response:', ' '.join([glove_index.get(word_idx) for word_idx in decoded_ids.reshape(-1).tolist()]))\n",
    "    \n",
    "    refered_frame_idx = np.argmax(frame_references, -1)\n",
    "    parsed_slots = parse_slots(current_input, np.argmax(result, axis=2).reshape(-1))\n",
    "    \n",
    "    if refered_frame_idx == 0:\n",
    "        print('Previous frame')\n",
    "    elif len(frame_references[0])-1 == refered_frame_idx:\n",
    "        print('New frame:', dict(frames[previous_active_frame_id], **parsed_slots))\n",
    "    else:\n",
    "        print('Refered frame:', frames[refered_frame_idx[0]-1])\n",
    "    print()\n",
    "\n",
    "        \n",
    "    print(frame_references)\n",
    "    \n",
    "#     print(np.argmax(fr_p, axis=-1))\n",
    "    print(parsed_slots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '<PAD>',\n",
       " 1: '<EOS>',\n",
       " 2: '<UNK>',\n",
       " 3: '<VAL.true>',\n",
       " 4: '<VAL.false>',\n",
       " 5: '<VAL.any>',\n",
       " 6: '<SLOT.<NO_SLOT>>',\n",
       " 7: '<SLOT.price>',\n",
       " 8: '<SLOT.min_duration>',\n",
       " 9: '<SLOT.str_date>',\n",
       " 10: '<SLOT.count_name>',\n",
       " 11: '<SLOT.dst_city>',\n",
       " 12: '<SLOT.category>',\n",
       " 13: '<SLOT.wifi>',\n",
       " 14: '<SLOT.dep_time_dst>',\n",
       " 15: '<SLOT.breakfast>',\n",
       " 16: '<SLOT.count>',\n",
       " 17: '<SLOT.university>',\n",
       " 18: '<SLOT.gym>',\n",
       " 19: '<SLOT.budget_ok>',\n",
       " 20: '<SLOT.park>',\n",
       " 21: '<SLOT.max_duration>',\n",
       " 22: '<SLOT.count_dst_city>',\n",
       " 23: '<SLOT.dep_time_or>',\n",
       " 24: '<SLOT.downtown>',\n",
       " 25: '<SLOT.vicinity>',\n",
       " 26: '<SLOT.count_amenities>',\n",
       " 27: '<SLOT.arr_time_or>',\n",
       " 28: '<SLOT.beach>',\n",
       " 29: '<SLOT.amenities>',\n",
       " 30: '<SLOT.count_category>',\n",
       " 31: '<SLOT.end_date>',\n",
       " 32: '<SLOT.name>',\n",
       " 33: '<SLOT.end_date_ok>',\n",
       " 34: '<SLOT.dst_city_ok>',\n",
       " 35: '<SLOT.arr_time_dst>',\n",
       " 36: '<SLOT.or_city>',\n",
       " 37: '<SLOT.spa>',\n",
       " 38: '<SLOT.n_children>',\n",
       " 39: '<SLOT.palace>',\n",
       " 40: '<SLOT.duration>',\n",
       " 41: '<SLOT.seat_ok>',\n",
       " 42: '<SLOT.flex>',\n",
       " 43: '<SLOT.shopping>',\n",
       " 44: '<SLOT.budget>',\n",
       " 45: '<SLOT.gst_rating>',\n",
       " 46: '<SLOT.seat>',\n",
       " 47: '<SLOT.museum>',\n",
       " 48: '<SLOT.airport>',\n",
       " 49: '<SLOT.market>',\n",
       " 50: '<SLOT.theatre>',\n",
       " 51: '<SLOT.mall>',\n",
       " 52: '<SLOT.impl_anaphora>',\n",
       " 53: '<SLOT.parking>',\n",
       " 54: '<SLOT.cathedral>',\n",
       " 55: '<SLOT.n_adults>',\n",
       " 56: '<SLOT.str_date_ok>',\n",
       " 57: ',',\n",
       " 58: 'the',\n",
       " 59: '.',\n",
       " 60: 'and',\n",
       " 61: 'to',\n",
       " 62: 'of',\n",
       " 63: 'a',\n",
       " 64: 'in',\n",
       " 65: 'is',\n",
       " 66: 'for',\n",
       " 67: ':',\n",
       " 68: 'i',\n",
       " 69: ')',\n",
       " 70: 'that',\n",
       " 71: '(',\n",
       " 72: 'you',\n",
       " 73: 'it',\n",
       " 74: 'on',\n",
       " 75: '-',\n",
       " 76: 'with',\n",
       " 77: \"'s\",\n",
       " 78: 'this',\n",
       " 79: 'by',\n",
       " 80: 'are',\n",
       " 81: 'at',\n",
       " 82: 'as',\n",
       " 83: 'be',\n",
       " 84: 'from',\n",
       " 85: 'have',\n",
       " 86: 'was',\n",
       " 87: 'or',\n",
       " 88: 'your',\n",
       " 89: 'not',\n",
       " 90: '...',\n",
       " 91: 'we',\n",
       " 92: '!',\n",
       " 93: 'but',\n",
       " 94: '?',\n",
       " 95: 'all',\n",
       " 96: 'will',\n",
       " 97: 'an',\n",
       " 98: 'my',\n",
       " 99: 'can',\n",
       " 100: 'they',\n",
       " 101: \"n't\",\n",
       " 102: 'do',\n",
       " 103: 'he',\n",
       " 104: 'more',\n",
       " 105: 'if',\n",
       " 106: 'one',\n",
       " 107: 'has',\n",
       " 108: 'so',\n",
       " 109: 'about',\n",
       " 110: 'new',\n",
       " 111: 'what',\n",
       " 112: 'his',\n",
       " 113: 'there',\n",
       " 114: 'up',\n",
       " 115: 'out',\n",
       " 116: ';',\n",
       " 117: 'their',\n",
       " 118: 'our',\n",
       " 119: \"'\",\n",
       " 120: 'like',\n",
       " 121: 'when',\n",
       " 122: '$',\n",
       " 123: 'just',\n",
       " 124: 'time',\n",
       " 125: '&',\n",
       " 126: 'me',\n",
       " 127: 'which',\n",
       " 128: 'who',\n",
       " 129: 'no',\n",
       " 130: 'would',\n",
       " 131: '/',\n",
       " 132: '1',\n",
       " 133: 'some',\n",
       " 134: 'get',\n",
       " 135: ']',\n",
       " 136: 'also',\n",
       " 137: 'other',\n",
       " 138: 'how',\n",
       " 139: 'may',\n",
       " 140: 'had',\n",
       " 141: 'am',\n",
       " 142: 'been',\n",
       " 143: '2',\n",
       " 144: 'her',\n",
       " 145: 'were',\n",
       " 146: 'them',\n",
       " 147: 'people',\n",
       " 148: 'she',\n",
       " 149: 'any',\n",
       " 150: 'now',\n",
       " 151: 'only',\n",
       " 152: 'pm',\n",
       " 153: 'first',\n",
       " 154: 'than',\n",
       " 155: 'good',\n",
       " 156: 'into',\n",
       " 157: 'its',\n",
       " 158: 'these',\n",
       " 159: 'us',\n",
       " 160: 'see',\n",
       " 161: 'here',\n",
       " 162: 'make',\n",
       " 163: 'home',\n",
       " 164: '3',\n",
       " 165: 'very',\n",
       " 166: 'over',\n",
       " 167: 'most',\n",
       " 168: 'then',\n",
       " 169: 'know',\n",
       " 170: 'said',\n",
       " 171: 'after',\n",
       " 172: 'well',\n",
       " 173: 'use',\n",
       " 174: 'two',\n",
       " 175: '%',\n",
       " 176: 'did',\n",
       " 177: 'could',\n",
       " 178: 'day',\n",
       " 179: 'great',\n",
       " 180: 'free',\n",
       " 181: 'many',\n",
       " 182: 'back',\n",
       " 183: 'way',\n",
       " 184: 'work',\n",
       " 185: 'because',\n",
       " 186: \"'m\",\n",
       " 187: 'best',\n",
       " 188: 'should',\n",
       " 189: 'even',\n",
       " 190: 'year',\n",
       " 191: 'think',\n",
       " 192: 'years',\n",
       " 193: 'much',\n",
       " 194: 'does',\n",
       " 195: 'where',\n",
       " 196: '4',\n",
       " 197: 'go',\n",
       " 198: 'love',\n",
       " 199: 'need',\n",
       " 200: 'last',\n",
       " 201: 'find',\n",
       " 202: '=',\n",
       " 203: 'world',\n",
       " 204: 'really',\n",
       " 205: 'information',\n",
       " 206: 'through',\n",
       " 207: 'want',\n",
       " 208: '#',\n",
       " 209: '5',\n",
       " 210: 'him',\n",
       " 211: 'right',\n",
       " 212: 'take',\n",
       " 213: 'such',\n",
       " 214: 'made',\n",
       " 215: 'those',\n",
       " 216: 'business',\n",
       " 217: 'life',\n",
       " 218: 'before',\n",
       " 219: 'being',\n",
       " 220: 'off',\n",
       " 221: 'used',\n",
       " 222: 'help',\n",
       " 223: '10',\n",
       " 224: 'while',\n",
       " 225: \"'re\",\n",
       " 226: 'too',\n",
       " 227: 'still',\n",
       " 228: \"'ve\",\n",
       " 229: 'down',\n",
       " 230: 'going',\n",
       " 231: 'part',\n",
       " 232: 'online',\n",
       " 233: 'each',\n",
       " 234: 'little',\n",
       " 235: 'high',\n",
       " 236: '+',\n",
       " 237: 'look',\n",
       " 238: 'around',\n",
       " 239: 'same',\n",
       " 240: 'game',\n",
       " 241: 'read',\n",
       " 242: 'service',\n",
       " 243: 'long',\n",
       " 244: 'why',\n",
       " 245: 'school',\n",
       " 246: 'state',\n",
       " 247: '6',\n",
       " 248: 'city',\n",
       " 249: 'own',\n",
       " 250: 'every',\n",
       " 251: 'system',\n",
       " 252: 'next',\n",
       " 253: \"'ll\",\n",
       " 254: 'news',\n",
       " 255: 'site',\n",
       " 256: 'say',\n",
       " 257: 'got',\n",
       " 258: 'both',\n",
       " 259: 'under',\n",
       " 260: 'top',\n",
       " 261: 'set',\n",
       " 262: 'another',\n",
       " 263: 'since',\n",
       " 264: 'things',\n",
       " 265: 'available',\n",
       " 266: 'show',\n",
       " 267: 'place',\n",
       " 268: 'using',\n",
       " 269: 'better',\n",
       " 270: 'never',\n",
       " 271: 'please',\n",
       " 272: 'come',\n",
       " 273: 'big',\n",
       " 274: 'today',\n",
       " 275: 's',\n",
       " 276: 'family',\n",
       " 277: 'services',\n",
       " 278: 'full',\n",
       " 279: 'something',\n",
       " 280: 'number',\n",
       " 281: 'company',\n",
       " 282: 'few',\n",
       " 283: '7',\n",
       " 284: 'price',\n",
       " 285: 'ca',\n",
       " 286: 'between',\n",
       " 287: 'days',\n",
       " 288: 'book',\n",
       " 289: '0',\n",
       " 290: 'name',\n",
       " 291: 'view',\n",
       " 292: 'found',\n",
       " 293: 'ago',\n",
       " 294: 'real',\n",
       " 295: 'without',\n",
       " 296: 'old',\n",
       " 297: 'search',\n",
       " 298: 'always',\n",
       " 299: 'house',\n",
       " 300: 'three',\n",
       " 301: '8',\n",
       " 302: 'man',\n",
       " 303: 'must',\n",
       " 304: 'during',\n",
       " 305: 'again',\n",
       " 306: 'end',\n",
       " 307: '12',\n",
       " 308: 'different',\n",
       " 309: 'lot',\n",
       " 310: 'looking',\n",
       " 311: 'week',\n",
       " 312: 'sure',\n",
       " 313: 'group',\n",
       " 314: 'give',\n",
       " 315: '20',\n",
       " 316: 'team',\n",
       " 317: 'times',\n",
       " 318: 'let',\n",
       " 319: 'car',\n",
       " 320: 'area',\n",
       " 321: 'buy',\n",
       " 322: 'money',\n",
       " 323: 'water',\n",
       " 324: 'keep',\n",
       " 325: 'web',\n",
       " 326: 'data',\n",
       " 327: 'live',\n",
       " 328: 'small',\n",
       " 329: 'play',\n",
       " 330: 'including',\n",
       " 331: 'x',\n",
       " 332: 'thing',\n",
       " 333: 'list',\n",
       " 334: 'put',\n",
       " 335: 'children',\n",
       " 336: 'design',\n",
       " 337: 'women',\n",
       " 338: 'might',\n",
       " 339: 'white',\n",
       " 340: 'public',\n",
       " 341: 'point',\n",
       " 342: 'order',\n",
       " 343: 'call',\n",
       " 344: 'second',\n",
       " 345: 'local',\n",
       " 346: 'says',\n",
       " 347: 'case',\n",
       " 348: 'care',\n",
       " 349: 'program',\n",
       " 350: 'night',\n",
       " 351: '15',\n",
       " 352: 'blog',\n",
       " 353: 'away',\n",
       " 354: 'start',\n",
       " 355: 'review',\n",
       " 356: 'left',\n",
       " 357: 'however',\n",
       " 358: 'center',\n",
       " 359: 'feel',\n",
       " 360: 'having',\n",
       " 361: '11',\n",
       " 362: 'website',\n",
       " 363: 'line',\n",
       " 364: 'thanks',\n",
       " 365: 'food',\n",
       " 366: 'ever',\n",
       " 367: '9',\n",
       " 368: 'open',\n",
       " 369: 'university',\n",
       " 370: 'room',\n",
       " 371: 'though',\n",
       " 372: '30',\n",
       " 373: 'god',\n",
       " 374: 'product',\n",
       " 375: 'change',\n",
       " 376: 'making',\n",
       " 377: 'experience',\n",
       " 378: 'add',\n",
       " 379: 'internet',\n",
       " 380: 'hotel',\n",
       " 381: 'check',\n",
       " 382: 'job',\n",
       " 383: 'getting',\n",
       " 384: 'date',\n",
       " 385: \"'d\",\n",
       " 386: 'quality',\n",
       " 387: 'once',\n",
       " 388: 'course',\n",
       " 389: 'hard',\n",
       " 390: 'within',\n",
       " 391: 'contact',\n",
       " 392: 'until',\n",
       " 393: 'try',\n",
       " 394: 'sale',\n",
       " 395: 'games',\n",
       " 396: 'side',\n",
       " 397: 'able',\n",
       " 398: 'phone',\n",
       " 399: 'research',\n",
       " 400: 'community',\n",
       " 401: 'working',\n",
       " 402: 'march',\n",
       " 403: 'yet',\n",
       " 404: 'months',\n",
       " 405: 'body',\n",
       " 406: 'easy',\n",
       " 407: 'done',\n",
       " 408: 'light',\n",
       " 409: 'de',\n",
       " 410: 'country',\n",
       " 411: 'provide',\n",
       " 412: 'market',\n",
       " 413: 'results',\n",
       " 414: 'large',\n",
       " 415: 'person',\n",
       " 416: 'actually',\n",
       " 417: 'less',\n",
       " 418: 'office',\n",
       " 419: 'enough',\n",
       " 420: 'men',\n",
       " 421: 'june',\n",
       " 422: 'following',\n",
       " 423: 'special',\n",
       " 424: 'international',\n",
       " 425: 'states',\n",
       " 426: 'report',\n",
       " 427: 'makes',\n",
       " 428: 'per',\n",
       " 429: 'important',\n",
       " 430: 'united',\n",
       " 431: 'doing',\n",
       " 432: 'size',\n",
       " 433: 'hours',\n",
       " 434: 'red',\n",
       " 435: 'john',\n",
       " 436: 'south',\n",
       " 437: 'project',\n",
       " 438: 'thought',\n",
       " 439: 'nice',\n",
       " 440: 'based',\n",
       " 441: 'run',\n",
       " 442: '100',\n",
       " 443: 'type',\n",
       " 444: 'history',\n",
       " 445: 'least',\n",
       " 446: 'friends',\n",
       " 447: '18',\n",
       " 448: '14',\n",
       " 449: '13',\n",
       " 450: 'email',\n",
       " 451: 'party',\n",
       " 452: 'general',\n",
       " 453: 'north',\n",
       " 454: '16',\n",
       " 455: 'bad',\n",
       " 456: 'far',\n",
       " 457: '25',\n",
       " 458: 'head',\n",
       " 459: 'problem',\n",
       " 460: 'already',\n",
       " 461: 'called',\n",
       " 462: 'process',\n",
       " 463: 'fun',\n",
       " 464: 'york',\n",
       " 465: 'someone',\n",
       " 466: 'hope',\n",
       " 467: 'students',\n",
       " 468: 'watch',\n",
       " 469: 'hot',\n",
       " 470: 'photo',\n",
       " 471: 'level',\n",
       " 472: 'movie',\n",
       " 473: 'together',\n",
       " 474: 'needs',\n",
       " 475: 'others',\n",
       " 476: '24',\n",
       " 477: 'include',\n",
       " 478: 'young',\n",
       " 479: 'season',\n",
       " 480: 'version',\n",
       " 481: 'offer',\n",
       " 482: 'went',\n",
       " 483: 'form',\n",
       " 484: 'anything',\n",
       " 485: 'several',\n",
       " 486: 'file',\n",
       " 487: 'bit',\n",
       " 488: 'road',\n",
       " 489: 'tell',\n",
       " 490: '@',\n",
       " 491: 'link',\n",
       " 492: 'pretty',\n",
       " 493: 'often',\n",
       " 494: 'four',\n",
       " 495: 'park',\n",
       " 496: 'came',\n",
       " 497: 'hand',\n",
       " 498: 'yes',\n",
       " 499: 'everything',\n",
       " 500: 'green',\n",
       " 501: 'share',\n",
       " 502: 'access',\n",
       " 503: 'fact',\n",
       " 504: 'reviews',\n",
       " 505: 'visit',\n",
       " 506: 'along',\n",
       " 507: 'become',\n",
       " 508: 'points',\n",
       " 509: 'plan',\n",
       " 510: 'added',\n",
       " 511: 'october',\n",
       " 512: 'believe',\n",
       " 513: 'technology',\n",
       " 514: 'possible',\n",
       " 515: 'everyone',\n",
       " 516: 'past',\n",
       " 517: 'anyone',\n",
       " 518: 'below',\n",
       " 519: 'features',\n",
       " 520: 'means',\n",
       " 521: 'west',\n",
       " 522: 'current',\n",
       " 523: 'september',\n",
       " 524: 'details',\n",
       " 525: 'college',\n",
       " 526: 'nothing',\n",
       " 527: 'class',\n",
       " 528: 'card',\n",
       " 529: '17',\n",
       " 530: 'seen',\n",
       " 531: 'minutes',\n",
       " 532: 'august',\n",
       " 533: 'value',\n",
       " 534: 'beautiful',\n",
       " 535: 'early',\n",
       " 536: 'took',\n",
       " 537: 'true',\n",
       " 538: 'comes',\n",
       " 539: 'kind',\n",
       " 540: 'source',\n",
       " 541: 'film',\n",
       " 542: 'learn',\n",
       " 543: 'low',\n",
       " 544: 'happy',\n",
       " 545: 'question',\n",
       " 546: 'front',\n",
       " 547: 'kids',\n",
       " 548: 'property',\n",
       " 549: 'probably',\n",
       " 550: 'short',\n",
       " 551: 'above',\n",
       " 552: 'computer',\n",
       " 553: 'whole',\n",
       " 554: 'either',\n",
       " 555: 'given',\n",
       " 556: 'example',\n",
       " 557: 'heart',\n",
       " 558: 'near',\n",
       " 559: 'parts',\n",
       " 560: 'member',\n",
       " 561: 'future',\n",
       " 562: 'whether',\n",
       " 563: 'building',\n",
       " 564: 'insurance',\n",
       " 565: 'girl',\n",
       " 566: 'c',\n",
       " 567: '21',\n",
       " 568: 'energy',\n",
       " 569: '19',\n",
       " 570: 'million',\n",
       " 571: 'child',\n",
       " 572: 'face',\n",
       " 573: 'maybe',\n",
       " 574: 'pay',\n",
       " 575: 'mind',\n",
       " 576: 'thank',\n",
       " 577: 'close',\n",
       " 578: '22',\n",
       " 579: 'complete',\n",
       " 580: 'main',\n",
       " 581: 'trying',\n",
       " 582: 'location',\n",
       " 583: 'later',\n",
       " 584: 'user',\n",
       " 585: 'offers',\n",
       " 586: 'month',\n",
       " 587: 'save',\n",
       " 588: 'idea',\n",
       " 589: 'human',\n",
       " 590: 'words',\n",
       " 591: 'works',\n",
       " 592: 'travel',\n",
       " 593: 'perfect',\n",
       " 594: 'total',\n",
       " 595: 'cost',\n",
       " 596: 'looks',\n",
       " 597: 'questions',\n",
       " 598: 'almost',\n",
       " 599: 'original',\n",
       " 600: 'style',\n",
       " 601: 'space',\n",
       " 602: 'action',\n",
       " 603: 'sales',\n",
       " 604: 'taking',\n",
       " 605: 'quite',\n",
       " 606: 'age',\n",
       " 607: '50',\n",
       " 608: 'club',\n",
       " 609: 'living',\n",
       " 610: 'known',\n",
       " 611: 'stop',\n",
       " 612: 'posts',\n",
       " 613: 'oh',\n",
       " 614: '\\\\',\n",
       " 615: 'drive',\n",
       " 616: 'talk',\n",
       " 617: 'study',\n",
       " 618: 'via',\n",
       " 619: 'baby',\n",
       " 620: 'b',\n",
       " 621: 'issue',\n",
       " 622: 'coming',\n",
       " 623: 'major',\n",
       " 624: 'five',\n",
       " 625: 'mean',\n",
       " 626: 'america',\n",
       " 627: 'key',\n",
       " 628: 'enjoy',\n",
       " 629: 'range',\n",
       " 630: 'rate',\n",
       " 631: 'told',\n",
       " 632: 'simple',\n",
       " 633: '23',\n",
       " 634: 'seems',\n",
       " 635: 'ask',\n",
       " 636: 'court',\n",
       " 637: 'due',\n",
       " 638: 'sound',\n",
       " 639: 'friend',\n",
       " 640: 'send',\n",
       " 641: 'across',\n",
       " 642: 'word',\n",
       " 643: 'remember',\n",
       " 644: 'leave',\n",
       " 645: 'according',\n",
       " 646: 'soon',\n",
       " 647: 'wanted',\n",
       " 648: 'problems',\n",
       " 649: 'else',\n",
       " 650: 'private',\n",
       " 651: 'includes',\n",
       " 652: 'english',\n",
       " 653: 'rather',\n",
       " 654: 'cover',\n",
       " 655: 'beach',\n",
       " 656: 'issues',\n",
       " 657: 'stay',\n",
       " 658: 'taken',\n",
       " 659: 'message',\n",
       " 660: 'girls',\n",
       " 661: 'reason',\n",
       " 662: 'pictures',\n",
       " 663: 'address',\n",
       " 664: 'financial',\n",
       " 665: 'turn',\n",
       " 666: 'guide',\n",
       " 667: 'although',\n",
       " 668: 'especially',\n",
       " 669: 'move',\n",
       " 670: 'prices',\n",
       " 671: 'half',\n",
       " 672: 'star',\n",
       " 673: 'simply',\n",
       " 674: 'estate',\n",
       " 675: 'continue',\n",
       " 676: 'running',\n",
       " 677: 'woman',\n",
       " 678: 'weeks',\n",
       " 679: 'latest',\n",
       " 680: 'return',\n",
       " 681: '26',\n",
       " 682: 'la',\n",
       " 683: '28',\n",
       " 684: 'title',\n",
       " 685: 'summer',\n",
       " 686: 'provides',\n",
       " 687: 'picture',\n",
       " 688: 'deal',\n",
       " 689: 'note',\n",
       " 690: 'm',\n",
       " 691: 'win',\n",
       " 692: 'paper',\n",
       " 693: 'town',\n",
       " 694: 'meet',\n",
       " 695: 'hair',\n",
       " 696: 'understand',\n",
       " 697: 'friday',\n",
       " 698: 'further',\n",
       " 699: 'follow',\n",
       " 700: 'application',\n",
       " 701: 't',\n",
       " 702: 'account',\n",
       " 703: 'asked',\n",
       " 704: 'plus',\n",
       " 705: 'staff',\n",
       " 706: 'death',\n",
       " 707: 'bring',\n",
       " 708: 'sports',\n",
       " 709: 'lost',\n",
       " 710: 'google',\n",
       " 711: 'gold',\n",
       " 712: 'london',\n",
       " 713: 'gets',\n",
       " 714: 'among',\n",
       " 715: 'shop',\n",
       " 716: 'upon',\n",
       " 717: 'guy',\n",
       " 718: '27',\n",
       " 719: 'wedding',\n",
       " 720: 'subject',\n",
       " 721: 'd',\n",
       " 722: 'instead',\n",
       " 723: 'morning',\n",
       " 724: 'usually',\n",
       " 725: 'clear',\n",
       " 726: 'couple',\n",
       " 727: 'standard',\n",
       " 728: 'present',\n",
       " 729: 'recent',\n",
       " 730: 'san',\n",
       " 731: 'currently',\n",
       " 732: 'etc.',\n",
       " 733: 'daily',\n",
       " 734: 'record',\n",
       " 735: 'stuff',\n",
       " 736: 'matter',\n",
       " 737: 'required',\n",
       " 738: 'fire',\n",
       " 739: 'inside',\n",
       " 740: 'needed',\n",
       " 741: 'sun',\n",
       " 742: 'writing',\n",
       " 743: 'favorite',\n",
       " 744: 'final',\n",
       " 745: 'various',\n",
       " 746: 'behind',\n",
       " 747: 'third',\n",
       " 748: 'dog',\n",
       " 749: 'provided',\n",
       " 750: 'u',\n",
       " 751: 'saw',\n",
       " 752: 'cool',\n",
       " 753: 'guys',\n",
       " 754: 'california',\n",
       " 755: 'popular',\n",
       " 756: 'interest',\n",
       " 757: 'located',\n",
       " 758: 'meeting',\n",
       " 759: 'takes',\n",
       " 760: 'cheap',\n",
       " 761: 'fast',\n",
       " 762: 'choose',\n",
       " 763: 'similar',\n",
       " 764: 'hit',\n",
       " 765: 'write',\n",
       " 766: 'cut',\n",
       " 767: '29',\n",
       " 768: 'n',\n",
       " 769: 'users',\n",
       " 770: 'areas',\n",
       " 771: 'info',\n",
       " 772: 'sites',\n",
       " 773: 'sunday',\n",
       " 774: 'result',\n",
       " 775: 'amazing',\n",
       " 776: 'yourself',\n",
       " 777: 'saturday',\n",
       " 778: 'wo',\n",
       " 779: 'terms',\n",
       " 780: 'bill',\n",
       " 781: 'land',\n",
       " 782: 'e',\n",
       " 783: 'fine',\n",
       " 784: 'cause',\n",
       " 785: 'rest',\n",
       " 786: 'goes',\n",
       " 787: 'wrong',\n",
       " 788: 'outside',\n",
       " 789: 'ready',\n",
       " 790: 'sometimes',\n",
       " 791: 'author',\n",
       " 792: 'amount',\n",
       " 793: 'sign',\n",
       " 794: 'customer',\n",
       " 795: 'police',\n",
       " 796: 'changes',\n",
       " 797: 'join',\n",
       " 798: 'longer',\n",
       " 799: 'usa',\n",
       " 800: 'recently',\n",
       " 801: 'finally',\n",
       " 802: 'student',\n",
       " 803: 'myself',\n",
       " 804: 'bank',\n",
       " 805: 'choice',\n",
       " 806: 'previous',\n",
       " 807: 'hotels',\n",
       " 808: 'step',\n",
       " 809: 'w',\n",
       " 810: 'washington',\n",
       " 811: 'interesting',\n",
       " 812: 'ways',\n",
       " 813: 'late',\n",
       " 814: 'customers',\n",
       " 815: 'global',\n",
       " 816: 'period',\n",
       " 817: 'category',\n",
       " 818: 'welcome',\n",
       " 819: 'mother',\n",
       " 820: 'bar',\n",
       " 821: 'hear',\n",
       " 822: 'homes',\n",
       " 823: 'shall',\n",
       " 824: 'received',\n",
       " 825: 'king',\n",
       " 826: 'forward',\n",
       " 827: 'description',\n",
       " 828: 'answer',\n",
       " 829: 'worth',\n",
       " 830: 'certain',\n",
       " 831: 'additional',\n",
       " 832: 'fall',\n",
       " 833: 'heard',\n",
       " 834: 'gift',\n",
       " 835: 'bed',\n",
       " 836: 'excellent',\n",
       " 837: 'st.',\n",
       " 838: 'practice',\n",
       " 839: 'brand',\n",
       " 840: 'wish',\n",
       " 841: 'wait',\n",
       " 842: 'included',\n",
       " 843: 'sense',\n",
       " 844: 'monday',\n",
       " 845: 'lol',\n",
       " 846: 'learning',\n",
       " 847: 'saying',\n",
       " 848: 'quote',\n",
       " 849: 'huge',\n",
       " 850: 'thinking',\n",
       " 851: 'six',\n",
       " 852: 'super',\n",
       " 853: 'likely',\n",
       " 854: 'society',\n",
       " 855: 'update',\n",
       " 856: 'options',\n",
       " 857: '40',\n",
       " 858: 'son',\n",
       " 859: 'engine',\n",
       " 860: 'wrote',\n",
       " 861: 'addition',\n",
       " 862: 'ideas',\n",
       " 863: 'wide',\n",
       " 864: 'hold',\n",
       " 865: 'chance',\n",
       " 866: 'higher',\n",
       " 867: 'increase',\n",
       " 868: 'average',\n",
       " 869: 'canada',\n",
       " 870: 'manager',\n",
       " 871: 'limited',\n",
       " 872: 'parents',\n",
       " 873: 'profile',\n",
       " 874: '31',\n",
       " 875: 'allow',\n",
       " 876: 'shot',\n",
       " 877: 'round',\n",
       " 878: 'purchase',\n",
       " 879: 'island',\n",
       " 880: 'clean',\n",
       " 881: 'specific',\n",
       " 882: 'id',\n",
       " 883: 'tour',\n",
       " 884: 'likes',\n",
       " 885: 'lower',\n",
       " 886: 'starting',\n",
       " 887: 'risk',\n",
       " 888: 'river',\n",
       " 889: 'seem',\n",
       " 890: 'quick',\n",
       " 891: 'father',\n",
       " 892: 'planning',\n",
       " 893: 'middle',\n",
       " 894: 'machine',\n",
       " 895: 'wife',\n",
       " 896: 'receive',\n",
       " 897: 'district',\n",
       " 898: 'base',\n",
       " 899: 'thursday',\n",
       " 900: 'entire',\n",
       " 901: 'ones',\n",
       " 902: 'double',\n",
       " 903: 'success',\n",
       " 904: 'pass',\n",
       " 905: 'silver',\n",
       " 906: 'opportunity',\n",
       " 907: 'weather',\n",
       " 908: 'tuesday',\n",
       " 909: 'activities',\n",
       " 910: 'official',\n",
       " 911: 'extra',\n",
       " 912: 'wednesday',\n",
       " 913: 'st',\n",
       " 914: 'response',\n",
       " 915: 'fit',\n",
       " 916: 'easily',\n",
       " 917: 'hour',\n",
       " 918: 'lives',\n",
       " 919: 'holiday',\n",
       " 920: 'wonderful',\n",
       " 921: 'tried',\n",
       " 922: 'particular',\n",
       " 923: 'perhaps',\n",
       " 924: 'moving',\n",
       " 925: 'agree',\n",
       " 926: 'ok',\n",
       " 927: 'awesome',\n",
       " 928: '2000',\n",
       " 929: 'ii',\n",
       " 930: 'weekend',\n",
       " 931: 'direct',\n",
       " 932: 'focus',\n",
       " 933: 'spring',\n",
       " 934: 'career',\n",
       " 935: 'floor',\n",
       " 936: 'former',\n",
       " 937: 'gave',\n",
       " 938: 'talking',\n",
       " 939: 'itself',\n",
       " 940: 'boy',\n",
       " 941: 'walk',\n",
       " 942: 'plans',\n",
       " 943: 'ground',\n",
       " 944: 'throughout',\n",
       " 945: 'giving',\n",
       " 946: 'commercial',\n",
       " 947: 'trip',\n",
       " 948: 'interested',\n",
       " 949: 'earth',\n",
       " 950: 'garden',\n",
       " 951: 'ball',\n",
       " 952: 'safe',\n",
       " 953: 'gives',\n",
       " 954: 'golf',\n",
       " 955: 'florida',\n",
       " 956: 'conditions',\n",
       " 957: 'pain',\n",
       " 958: 'sell',\n",
       " 959: 'fan',\n",
       " 960: 'mar',\n",
       " 961: 'decided',\n",
       " 962: 'consider',\n",
       " 963: 'sent',\n",
       " 964: 'shopping',\n",
       " 965: 'quickly',\n",
       " 966: 'guess',\n",
       " 967: 'stand',\n",
       " 968: 'moment',\n",
       " 969: 'break',\n",
       " 970: 'dead',\n",
       " 971: 'completely',\n",
       " 972: 'sorry',\n",
       " 973: 'fashion',\n",
       " 974: 'feature',\n",
       " 975: 'attention',\n",
       " 976: 'wants',\n",
       " 977: 'rating',\n",
       " 978: 'lots',\n",
       " 979: 'eye',\n",
       " 980: 'potential',\n",
       " 981: 'classic',\n",
       " 982: 'leading',\n",
       " 983: 'cup',\n",
       " 984: 'pick',\n",
       " 985: 'knew',\n",
       " 986: 'places',\n",
       " 987: 'looked',\n",
       " 988: 'cash',\n",
       " 989: 'character',\n",
       " 990: 'sweet',\n",
       " 991: 'regular',\n",
       " 992: 'ability',\n",
       " 993: 'involved',\n",
       " 994: 'difficult',\n",
       " 995: 'costs',\n",
       " 996: 'exactly',\n",
       " 997: 'r',\n",
       " 998: 'benefits',\n",
       " 999: 'request',\n",
       " ...}"
      ]
     },
     "execution_count": 936,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor 'Sum:0' shape=() dtype=float32>, <tf.Tensor 'Mean:0' shape=() dtype=float32>, <tf.Tensor 'Mean_1:0' shape=() dtype=float32>, <tf.Tensor 'Mean_2:0' shape=() dtype=float32>, <tf.Tensor 'Mean_3:0' shape=() dtype=float32>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class ConversationalModel():\n",
    "    \n",
    "    def __init__(self, inputs, input_lengths, last_responses, last_response_lengths, frame_slots, frame_values, frame_slot_counts, frame_value_lengths, embeddings_shape=None, trainable_embeddings=False, n_slots=5):\n",
    "        '''\n",
    "        :param inputs: Current user input [batch_size x n_tokens]\n",
    "        :param input_lengths: Number of tokens per input utterance [batch_size]\n",
    "        :param last_responses: Last agent responses [batch_size x n_tokens]\n",
    "        :param last_response_lengths: Number of tokens per response [batch_size]\n",
    "        :param frame_slots: Input frames slots [batch_size x n_frames x n_slots]\n",
    "        :param frame_values: Input frames values [batch_size x n_frames x n_slots x n_tokens]\n",
    "        :param frame_value_lengths: Input frame value lengths [batch_size x n_frames x n_slots]\n",
    "        '''\n",
    "        self._inputs = inputs\n",
    "        self._input_lenghts = input_lengths\n",
    "        self._last_responses = last_responses\n",
    "        self._last_response_lengths = last_response_lengths\n",
    "        self._frame_slots = frame_slots\n",
    "        self._frame_values = frame_values\n",
    "        self._frame_slot_counts = frame_slot_counts\n",
    "        self._frame_value_lengths = frame_value_lengths\n",
    "        \n",
    "        self._embeddings_shape = embeddings_shape\n",
    "        self._trainable_embeddings = trainable_embeddings\n",
    "        self._n_slots = n_slots\n",
    "        \n",
    "        self._le_cell_output_size = 300\n",
    "        self._attention_output_size = 600\n",
    "        self._slot_embeddings_size = 300\n",
    "\n",
    "    def build(self):\n",
    "        self._embeddings_module()\n",
    "        self._language_encoder_module()\n",
    "        self._informable_slots_parser()\n",
    "#         self._requestable_slots_parser()\n",
    "        self._frames_encoder_module()\n",
    "        self._frame_references_parser()\n",
    "\n",
    "    def embeddings_initializer(self):\n",
    "        _placeholder = tf.placeholder(tf.float32)\n",
    "        _op = self._word_embeddings.assign(_placeholder)\n",
    "        return _placeholder, _op\n",
    "        \n",
    "    def _embeddings_module(self):\n",
    "        with tf.name_scope('embeddings_module'):\n",
    "            self._word_embeddings = tf.Variable(\n",
    "                tf.random_normal(self._embeddings_shape, -.3, .3),\n",
    "                trainable = self._trainable_embeddings,\n",
    "                name = 'word_embeddings'\n",
    "            )\n",
    "            self._slot_embeddings = tf.Variable(\n",
    "                tf.random_normal([self._n_slots, self._slot_embeddings_size], -.3, .3),\n",
    "                trainable = True,\n",
    "                name = 'slot_embeddings'\n",
    "            )\n",
    "            \n",
    "            self._inputs_embedded = tf.nn.embedding_lookup(self._word_embeddings, self._inputs)\n",
    "            self._last_responses_embedded = tf.nn.embedding_lookup(self._word_embeddings, self._last_responses)\n",
    "            \n",
    "            self._frame_slots_embedded = tf.nn.embedding_lookup(self._slot_embeddings, self._frame_slots)\n",
    "            self._frame_values_embedded = tf.nn.embedding_lookup(self._word_embeddings, self._frame_values)\n",
    "        \n",
    "    def _language_encoder(self, inputs, sequence_lengths, name='language_encoder', reuse=False):\n",
    "        with tf.variable_scope(name, reuse=reuse):\n",
    "            zero_pad = tf.zeros([tf.shape(inputs)[0], 1, self._embeddings_shape[1]])\n",
    "            inputs_padded = tf.concat([zero_pad, inputs, zero_pad], 1)\n",
    "            \n",
    "            inputs_convolved = tf.layers.conv1d(\n",
    "                inputs_padded,\n",
    "                filters = self._embeddings_shape[1],\n",
    "                kernel_size = 3,\n",
    "                use_bias = False,\n",
    "                padding = 'valid',\n",
    "                name='outputs_conv'\n",
    "            )\n",
    "            \n",
    "            fw_cell = GRUCell(self._le_cell_output_size, activation=tf.nn.tanh)\n",
    "            bw_cell = GRUCell(self._le_cell_output_size, activation=tf.nn.tanh)\n",
    "\n",
    "            outputs, state = tf.nn.bidirectional_dynamic_rnn(\n",
    "                fw_cell, bw_cell,\n",
    "                inputs = inputs,\n",
    "                sequence_length = sequence_lengths,\n",
    "                dtype = tf.float32,\n",
    "            )\n",
    "            \n",
    "            return tf.concat(outputs, 2, name='le_outputs'), tf.concat(state, 1, name='le_state')\n",
    "    \n",
    "    def _language_encoder_module(self):\n",
    "        with tf.name_scope('language_encoder_module'):\n",
    "            self._inputs_encoded_outputs, self._inputs_encoded_state = self._language_encoder(\n",
    "                inputs = self._inputs_embedded,\n",
    "                sequence_lengths = self._input_lenghts\n",
    "            )\n",
    "            self._last_responses_encoded_outputs, self._last_responses_encoded_state = self._language_encoder(\n",
    "                inputs = self._last_responses_embedded,\n",
    "                sequence_lengths = self._last_response_lengths,\n",
    "                reuse = True\n",
    "            )\n",
    "    \n",
    "    def _informable_slots_parser(self):\n",
    "        with tf.name_scope('informable_slots_parser_module'):\n",
    "            e_inputs = tf.layers.dense(\n",
    "                self._inputs_encoded_outputs,\n",
    "                self._attention_output_size,\n",
    "                activation=tf.nn.tanh,\n",
    "                name='weights_projection'\n",
    "            )\n",
    "            e_last_responses = tf.layers.dense(\n",
    "                self._last_responses_encoded_outputs,\n",
    "                self._attention_output_size,\n",
    "                activation=tf.nn.tanh,\n",
    "                name='weights_projection',\n",
    "                reuse=True\n",
    "            )\n",
    "            \n",
    "            e = tf.matmul(e_inputs, e_last_responses, transpose_b=True, name='e')\n",
    "            beta = tf.matmul(tf.nn.softmax(e), self._last_responses_encoded_outputs)\n",
    "            \n",
    "            inputs_compared = tf.layers.dense(\n",
    "                tf.concat([self._inputs_encoded_outputs, beta], 2),\n",
    "                self._attention_output_size,\n",
    "                activation=tf.nn.tanh,\n",
    "                name='comparison'\n",
    "            )\n",
    "            \n",
    "            self._informable_slots_logits = tf.layers.dense(\n",
    "                inputs_compared,\n",
    "                self._n_slots,\n",
    "            )\n",
    "            self.informable_slots_p = tf.nn.softmax(self._informable_slots_logits)\n",
    "    \n",
    "    def _requestable_slots_parser(self):\n",
    "        pass\n",
    "    \n",
    "    def _frames_encoder_module(self):\n",
    "        with tf.name_scope('frames_encoder_module'):\n",
    "            batch_size, n_frames, n_slots, n_tokens, _ = tf.unstack(tf.shape(self._frame_values_embedded))\n",
    "            _, le_state = self._language_encoder(\n",
    "                tf.reshape(self._frame_values_embedded, [-1, n_tokens, self._embeddings_shape[1]]),\n",
    "                tf.reshape(self._frame_value_lengths, [-1]),\n",
    "                reuse=True\n",
    "            )\n",
    "            frames_slot_value = tf.concat([\n",
    "                tf.reshape(self._frame_slots_embedded, [batch_size*n_frames, n_slots, self._slot_embeddings_size]),\n",
    "                tf.reshape(le_state, [batch_size*n_frames, n_slots, 2*self._le_cell_output_size]),\n",
    "            ], 2)\n",
    "            \n",
    "            _, frames_encoder_state = tf.nn.dynamic_rnn(\n",
    "                GRUCell(2*self._le_cell_output_size, activation=tf.nn.tanh),\n",
    "                inputs = frames_slot_value,\n",
    "                sequence_length = tf.reshape(self._frame_slot_counts, [-1]),\n",
    "                dtype=tf.float32\n",
    "            )\n",
    "\n",
    "            self._frames_encoded = tf.reshape(frames_encoder_state, [batch_size, n_frames, 2*self._le_cell_output_size])\n",
    "            \n",
    "    def _frame_references_parser(self):\n",
    "        batch_size, n_tokens = tf.unstack(tf.shape(self._inputs))\n",
    "        token_slots = tf.matmul(\n",
    "            tf.reshape(self.informable_slots_p, [-1, self._n_slots]),\n",
    "            self._slot_embeddings\n",
    "        )\n",
    "        token_slot_value = tf.concat([\n",
    "            tf.reshape(token_slots, [batch_size, n_tokens, self._slot_embeddings_size]),\n",
    "            self._inputs_encoded_outputs,\n",
    "        ], 2)\n",
    "        token_slot_projected = tf.layers.dense(\n",
    "            token_slot_value,\n",
    "            2*self._le_cell_output_size,\n",
    "            activation = tf.nn.tanh\n",
    "        )\n",
    "        \n",
    "        # Projection\n",
    "        e_tokens = tf.layers.dense(\n",
    "            token_slot_projected,\n",
    "            self._attention_output_size,\n",
    "            activation = tf.nn.tanh,\n",
    "            name='frames_attention_weights_projection',\n",
    "        )\n",
    "        e_frames = tf.layers.dense(\n",
    "            self._frames_encoded,\n",
    "            self._attention_output_size,\n",
    "            activation = tf.nn.tanh,\n",
    "            name='frames_attention_weights_projection',\n",
    "            reuse=True\n",
    "        )\n",
    "        \n",
    "        self._frame_references_logits = tf.matmul(e_tokens, e_frames, transpose_b=True, name='e')\n",
    "        self.frame_references_p = tf.nn.softmax(self._frame_references_logits)\n",
    "        \n",
    "    def losses(self, informable_slots_targets, frame_references_targets):\n",
    "        informable_slots_stepwise_ce = tf.nn.softmax_cross_entropy_with_logits(\n",
    "            labels = tf.one_hot(informable_slots_targets, self._n_slots),\n",
    "            logits = self._informable_slots_logits\n",
    "        )    \n",
    "        informable_slots_loss = tf.reduce_mean(informable_slots_stepwise_ce)\n",
    "        informable_slots_accuracy = tf.reduce_mean(tf.cast(tf.equal(informable_slots_targets, tf.argmax(self.informable_slots_p, -1)), tf.float32))\n",
    "        \n",
    "        frame_references_framewise_ce = tf.nn.softmax_cross_entropy_with_logits(\n",
    "            labels = tf.one_hot(frame_references_targets, tf.shape(self._frame_slots)[1]+1),\n",
    "            logits = self._frame_references_logits,\n",
    "        )\n",
    "        \n",
    "        frame_references_loss = tf.reduce_mean(frame_references_framewise_ce)\n",
    "        frame_references_accuracy = tf.reduce_mean(tf.cast(tf.equal(frame_references_targets, tf.argmax(self.frame_references_p, -1)), tf.float32))\n",
    "        \n",
    "        total_loss = tf.reduce_sum([informable_slots_loss, frame_references_loss])\n",
    "\n",
    "        tf.summary.scalar('total_loss', total_loss)\n",
    "        tf.summary.scalar('informable_slots_loss', informable_slots_loss)\n",
    "        tf.summary.scalar('informable_slots_accuracy', informable_slots_accuracy)\n",
    "        tf.summary.scalar('frame_references_loss', frame_references_loss)\n",
    "        tf.summary.scalar('frame_references_accuracy', frame_references_accuracy)\n",
    "        \n",
    "        return (\n",
    "            total_loss,\n",
    "            informable_slots_loss,\n",
    "            informable_slots_accuracy,\n",
    "            frame_references_loss,\n",
    "            frame_references_accuracy,\n",
    "        )\n",
    "    \n",
    "    \n",
    "with tf.Graph().as_default():\n",
    "    inputs_ph = tf.placeholder(tf.int64, [64, 10])\n",
    "    input_lengths_ph = tf.placeholder(tf.int64, [64])\n",
    "    last_responses_ph = tf.placeholder(tf.int64, [64,7])\n",
    "    last_response_lengths_ph = tf.placeholder(tf.int64, [64])\n",
    "    frame_slots_ph = tf.placeholder(tf.int64, [64,3,5])\n",
    "    frame_values_ph = tf.placeholder(tf.int64, [64,3,5,10])\n",
    "    frame_slot_counts_ph = tf.placeholder(tf.int64, [64,3])\n",
    "    frame_value_lengths_ph = tf.placeholder(tf.int64, [64,3,5])\n",
    "    \n",
    "    informable_slots_targets_ph = tf.placeholder(tf.int64, [64,10])\n",
    "    frame_references_targets_ph = tf.placeholder(tf.int64, [64,10])\n",
    "    \n",
    "    model = ConversationalModel(inputs_ph, input_lengths_ph, last_responses_ph, last_response_lengths_ph, frame_slots_ph, frame_values_ph, frame_slot_counts_ph, frame_value_lengths_ph, embeddings_shape=[9600,300])\n",
    "    model.build()\n",
    "    \n",
    "    print(model.losses(informable_slots_targets_ph, frame_references_targets_ph))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    inputs_ph = tf.placeholder(tf.int64, [None, None])\n",
    "    input_lengths_ph = tf.placeholder(tf.int64, [None])\n",
    "    last_responses_ph = tf.placeholder(tf.int64, [None, None])\n",
    "    last_response_lengths_ph = tf.placeholder(tf.int64, [None])\n",
    "    frame_slots_ph = tf.placeholder(tf.int64, [None, None, None])\n",
    "    frame_values_ph = tf.placeholder(tf.int64, [None, None, None, None])\n",
    "    frame_slot_counts_ph = tf.placeholder(tf.int64, [None, None])\n",
    "    frame_value_lengths_ph = tf.placeholder(tf.int64, [None, None, None])\n",
    "    \n",
    "    informable_slots_targets_ph = tf.placeholder(tf.int64, [None, None])\n",
    "    frame_references_targets_ph = tf.placeholder(tf.int64, [None, None])\n",
    "    \n",
    "    model = ConversationalModel(inputs_ph, input_lengths_ph, last_responses_ph, last_response_lengths_ph, frame_slots_ph, frame_values_ph, frame_slot_counts_ph, frame_value_lengths_ph, embeddings_shape=[len(embeddings),300], n_slots=len(slots_dictionary))\n",
    "    model.build()\n",
    "    \n",
    "    embeddings_ph, embeddings_init_op = model.embeddings_initializer()\n",
    "    \n",
    "    total_loss, informable_slots_loss, informable_slots_accuracy, frame_references_loss, frame_references_accuracy = model.losses(informable_slots_targets_ph, frame_references_targets_ph)\n",
    "    train_op = tf.train.AdamOptimizer().minimize(total_loss)\n",
    "    \n",
    "    saver = tf.train.Saver(max_to_keep=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 6.75288 IS loss: 3.99973 IS acc: 0.0388105 FR loss: 2.75315 FR acc: 0.165827\n",
      "Total loss: 3.5116 IS loss: 2.26261 IS acc: 0.942857 FR loss: 1.24899 FR acc: 0.984821\n",
      "Total loss: 3.56339 IS loss: 1.73722 IS acc: 0.946484 FR loss: 1.82617 FR acc: 0.982031\n",
      "Total loss: 2.28559 IS loss: 1.13627 IS acc: 0.962402 FR loss: 1.14931 FR acc: 0.982422\n",
      "Interrupted\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(embeddings_init_op, feed_dict={embeddings_ph: embeddings})\n",
    "    \n",
    "    try:\n",
    "        for e in range(30):\n",
    "            i = 0\n",
    "            for (inputs, input_lengths, previous_responses, previous_response_lengths, frames_slot_counts, frames_value_lengths, frames_slots, frames_values, informable_slots_targets, frame_references_targets) in samples_iterator(train_data):\n",
    "                i += 1\n",
    "                fd = {\n",
    "                    inputs_ph: inputs,\n",
    "                    input_lengths_ph: input_lengths,\n",
    "                    last_responses_ph: previous_responses,\n",
    "                    last_response_lengths_ph: previous_response_lengths,\n",
    "                    frame_slots_ph: frames_slots,\n",
    "                    frame_values_ph: frames_values,\n",
    "                    frame_slot_counts_ph: frames_slot_counts,\n",
    "                    frame_value_lengths_ph: frames_value_lengths,\n",
    "                    informable_slots_targets_ph: informable_slots_targets,\n",
    "                    frame_references_targets_ph: frame_references_targets\n",
    "                }\n",
    "                \n",
    "                _, total_loss_val, informable_slots_loss_val, informable_slots_accuracy_val, frame_references_loss_val, frame_references_accuracy_val = sess.run([train_op, total_loss, informable_slots_loss, informable_slots_accuracy, frame_references_loss, frame_references_accuracy], feed_dict = fd)\n",
    "                print('Total loss:', total_loss_val, 'IS loss:', informable_slots_loss_val, 'IS acc:', informable_slots_accuracy_val, 'FR loss:', frame_references_loss_val, 'FR acc:', frame_references_accuracy_val)\n",
    "#                 if i % 20 == 0:\n",
    "#                     print('Epoch:', e, 'Step:', i, 'Loss:', loss_val, 'Accuracy:', accuracy_val)\n",
    "\n",
    "            saver.save(sess, '../checkpoints/conversational/intent_frame_ref_1/model', global_step=e)\n",
    "\n",
    "            losses, accuracies = [], []\n",
    "            for (inputs, input_lengths, previous_responses, previous_response_lengths, targets) in samples_iterator(test_data):\n",
    "                fd = {\n",
    "                    inputs_ph: inputs,\n",
    "                    input_lengths_ph: input_lengths,\n",
    "                    last_responses_ph: previous_responses,\n",
    "                    last_response_lengths_ph: previous_response_lengths,\n",
    "                    informable_slots_targets_ph: targets,\n",
    "                }\n",
    "\n",
    "                loss_val, accuracy_val = sess.run([informable_slots_loss, informable_slots_accuracy], feed_dict = fd)\n",
    "                losses.append(loss_val)\n",
    "                accuracies.append(accuracy_val)\n",
    "\n",
    "            print('Epoch:', e, 'Mean loss:', np.mean(losses), 'Mean accuracy:', np.mean(accuracies))\n",
    "            losses, accuracies = [], []\n",
    "    except KeyboardInterrupt:\n",
    "        print('Interrupted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../checkpoints/gcloud_intent_frames_4/checkpoints.ckpt-21\n",
      "[[[  9.99997973e-01   1.89331308e-06   3.18753521e-08   1.17094636e-07]\n",
      "  [  9.99651313e-01   2.84858339e-04   4.80335711e-06   5.90107593e-05]\n",
      "  [  9.99999762e-01   1.82410517e-07   8.70987310e-11   1.22497373e-10]\n",
      "  [  9.99763310e-01   2.25951866e-04   1.68528231e-06   9.11747793e-06]\n",
      "  [  9.99996781e-01   3.19054561e-06   6.29734265e-09   1.18549073e-08]\n",
      "  [  9.99998212e-01   1.84210762e-06   9.81873680e-11   1.29314712e-10]]]\n",
      "[[0 0 0 0 0 0]]\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "def embed_sentence(sentence):\n",
    "    return np.array([glove_dictionary.get(token, 2) for token in nltk.word_tokenize(str(sentence).lower())])\n",
    "\n",
    "def parse_slots(sentence, slot_ids):\n",
    "    tokens = nltk.word_tokenize(str(sentence).lower())\n",
    "    assert len(tokens) == len(slot_ids)\n",
    "    \n",
    "    resolved = []\n",
    "    for idx, slot_id in enumerate(slot_ids):\n",
    "        if slot_id > 0:\n",
    "            if len(resolved) == 0:\n",
    "                resolved.append([slot_id, tokens[idx]])\n",
    "            else:\n",
    "                if resolved[-1][0] == slot_id:\n",
    "                    resolved[-1].append(tokens[idx])\n",
    "                else:\n",
    "                    resolved.append([slot_id, tokens[idx]])\n",
    "    \n",
    "    return {slots_index.get(val[0]): ' '.join(val[1:]) for val in resolved}\n",
    "\n",
    "turn = frames_processed[12][1]\n",
    "\n",
    "previous_active_frame_id = 0\n",
    "frames = turn['frames']\n",
    "previous_response = turn['previous_response']\n",
    "current_input = turn['user_input']\n",
    "\n",
    "previous_response_embedding_ids = embed_sentence(previous_response)\n",
    "current_input_embedding_ids = embed_sentence(current_input)\n",
    "frames_embedded = embed_frames(frames)\n",
    "\n",
    "frames_slot_counts, frames_value_lengths, frames_slots, frames_values = pad_frames([frames_embedded], len(frames_embedded))\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    saver.restore(sess, '../checkpoints/gcloud_intent_frames_4/checkpoints.ckpt-21')\n",
    "    fd = {\n",
    "        inputs_ph: [current_input_embedding_ids],\n",
    "        input_lengths_ph: [len(current_input_embedding_ids)],\n",
    "        last_responses_ph: [previous_response_embedding_ids],\n",
    "        last_response_lengths_ph: [len(previous_response_embedding_ids)],\n",
    "        frame_slots_ph: frames_slots,\n",
    "        frame_values_ph: frames_values,\n",
    "        frame_slot_counts_ph: frames_slot_counts,\n",
    "        frame_value_lengths_ph: frames_value_lengths,\n",
    "    }\n",
    "    result, fr_p = sess.run([model.informable_slots_p, model.frame_references_p], feed_dict = fd)\n",
    "    \n",
    "    print(fr_p)\n",
    "    print(np.argmax(fr_p, axis=-1))\n",
    "    print(parse_slots(\n",
    "        current_input,\n",
    "        np.argmax(result, axis=2).reshape(-1)\n",
    "    ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
