{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn, seq2seq\n",
    "from tensorflow.python.layers.core import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent(hidden_size=300, n_slots=5, n_actions=3)\n"
     ]
    }
   ],
   "source": [
    "def add_pad_eos(indices, sequence_length, eos_token = 1, pre_pad = True):\n",
    "    batch_size, max_length = tf.unstack(tf.shape(indices))\n",
    "    \n",
    "    pad = tf.zeros([batch_size, 1], dtype=tf.int32)\n",
    "    if pre_pad:\n",
    "        eos = tf.one_hot(sequence_length+1, max_length+2, dtype=tf.int32) * eos_token\n",
    "        return tf.concat([pad, indices, pad], 1) + eos\n",
    "    else:\n",
    "        eos = tf.one_hot(sequence_length, max_length+2, dtype=tf.int32) * eos_token\n",
    "        return tf.concat([indices, pad, pad], 1) + eos\n",
    "\n",
    "class Agent(object):\n",
    "    \n",
    "    def __init__(self, word_embeddings_shape, n_slots, n_actions, trainable_embeddings=True, hidden_size=300, dropout=0.0, decoder_helper_initializer=None):\n",
    "        super(Agent, self).__init__()\n",
    "\n",
    "        # Conf\n",
    "        self._hidden_size = int(hidden_size)\n",
    "        self._word_embeddings_shape = list(word_embeddings_shape)\n",
    "        self._n_slots = int(n_slots)\n",
    "        self._n_actions = int(n_actions)\n",
    "        self._n_query_states = 3\n",
    "        self._trainable_embeddings = bool(trainable_embeddings)\n",
    "        self._dropout = dropout\n",
    "\n",
    "        self._decoder_helper_initializer = decoder_helper_initializer\n",
    "        tf.summary.scalar('dropout', self._dropout)\n",
    "\n",
    "        print('Agent(hidden_size={0}, n_slots={1}, n_actions={2})'.format(self._hidden_size, self._n_slots, self._n_actions))\n",
    "        \n",
    "        # Build\n",
    "        with tf.name_scope('agent'):\n",
    "            self._placeholders()\n",
    "            self._embeddings_module()\n",
    "            self._input_encoder()\n",
    "            self._slot_parser()\n",
    "            self._query_result_encoder()\n",
    "            self._context()\n",
    "            self._action_policy()\n",
    "            self._response_generator()\n",
    "        \n",
    "        self._saver_ops()\n",
    "        \n",
    "    @property\n",
    "    def context_state_size(self):\n",
    "        return 2*self._hidden_size\n",
    "        \n",
    "    def _saver_ops(self):\n",
    "        self.saver = tf.train.Saver(max_to_keep=None)\n",
    "\n",
    "    def _placeholders(self):\n",
    "        # Context\n",
    "        self.previous_context_state = tf.placeholder(tf.float32, [3, None, self.context_state_size])\n",
    "\n",
    "        # Inputs\n",
    "        self.inputs = tf.placeholder(tf.int32, [None, None])\n",
    "        self.inputs_length = tf.placeholder(tf.int32, [None])\n",
    "        self.previous_output = tf.placeholder(tf.int32, [None, None])\n",
    "        self.previous_output_length = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "        # Query result\n",
    "        self.query_result_state = tf.placeholder(tf.int32, [None])\n",
    "        self.query_result_slots = tf.placeholder(tf.int32, [None, None])\n",
    "        self.query_result_values = tf.placeholder(tf.int32, [None, None, None])\n",
    "        self.query_result_slots_count = tf.placeholder(tf.int32, [None])\n",
    "        self.query_result_values_length = tf.placeholder(tf.int32, [None, None])\n",
    "        \n",
    "    def _embeddings_module(self):\n",
    "        with tf.name_scope('embeddings'):\n",
    "            self._word_embeddings = tf.Variable(\n",
    "                tf.zeros(self._word_embeddings_shape),\n",
    "                trainable=self._trainable_embeddings, name='word_embeddings'\n",
    "            )\n",
    "            self._slot_embeddings = tf.Variable(\n",
    "                tf.random_normal([self._n_slots, self._word_embeddings_shape[1]]),\n",
    "                trainable=True, name='slot_embeddings'\n",
    "            )\n",
    "            \n",
    "            self._inputs_embedded = tf.nn.embedding_lookup(self._word_embeddings, self.inputs)\n",
    "            self._previous_output_embedded = tf.nn.embedding_lookup(self._word_embeddings, self.previous_output)\n",
    "            \n",
    "            self._query_result_slots_embedded = tf.nn.embedding_lookup(self._slot_embeddings, self.query_result_slots)\n",
    "            self._query_result_values_embedded = tf.nn.embedding_lookup(self._word_embeddings, self.query_result_values)\n",
    "            \n",
    "    def _rnn_cell(self, size=None, activation=None, dropout=None, residual=False):\n",
    "        cell = rnn.GRUCell((size or self._hidden_size), activation=activation)\n",
    "\n",
    "        if residual:\n",
    "            cell = rnn.ResidualWrapper(cell)\n",
    "\n",
    "        if dropout is not None:\n",
    "            cell = rnn.DropoutWrapper(cell, input_keep_prob=(1.0 - dropout))\n",
    "\n",
    "        return cell\n",
    "        \n",
    "    def _text_encoder(self, inputs, inputs_length, scope='text_encoder', reuse=False):\n",
    "        with tf.variable_scope(scope, reuse=reuse):\n",
    "            _outputs, _state = tf.nn.bidirectional_dynamic_rnn(\n",
    "                cell_fw = self._rnn_cell(activation=tf.nn.tanh),\n",
    "                cell_bw = self._rnn_cell(activation=tf.nn.tanh),\n",
    "                inputs = inputs,\n",
    "                sequence_length = inputs_length,\n",
    "                dtype = tf.float32\n",
    "            )\n",
    "\n",
    "        return (\n",
    "            tf.concat(_outputs, -1),\n",
    "            tf.concat(_state, -1)\n",
    "        )\n",
    " \n",
    "    def _input_encoder(self):\n",
    "        with tf.name_scope('inputs_encoder'):            \n",
    "            (self._inputs_encoder_outputs,\n",
    "             self._inputs_encoder_state) = self._text_encoder(self._inputs_embedded, self.inputs_length)\n",
    "            (self._previous_output_encoder_outputs,\n",
    "             self._previous_output_encoder_state) = self._text_encoder(self._previous_output_embedded, self.previous_output_length, reuse=True)\n",
    "            \n",
    "    def _slot_parser(self):\n",
    "        with tf.variable_scope('slot_parser'):\n",
    "            # Project text encoder state\n",
    "            e_inputs = tf.layers.dense(\n",
    "                self._inputs_encoder_outputs,\n",
    "                self._hidden_size,\n",
    "                activation = tf.nn.tanh,\n",
    "                name = 'inputs_e_projection'\n",
    "            )\n",
    "            e_previous_output = tf.layers.dense(\n",
    "                self._previous_output_encoder_outputs,\n",
    "                self._hidden_size,\n",
    "                activation = tf.nn.tanh,\n",
    "                name = 'inputs_e_projection',\n",
    "                reuse = True\n",
    "            )\n",
    "            \n",
    "            e = tf.matmul(e_inputs, e_previous_output, transpose_b=True, name='e')\n",
    "            beta = tf.matmul(tf.nn.softmax(e), self._previous_output_encoder_outputs)\n",
    "            \n",
    "            inputs_compared = tf.layers.dense(\n",
    "                tf.concat([self._inputs_encoder_outputs, beta], 2),\n",
    "                self._hidden_size,\n",
    "                activation = tf.nn.tanh\n",
    "            )\n",
    "            \n",
    "            # Final slot logits/probabilities\n",
    "            self._slot_logits = tf.layers.dense(\n",
    "                tf.layers.dropout(inputs_compared, rate=self._dropout),\n",
    "                self._n_slots\n",
    "            )\n",
    "            self.slot_probabilities = tf.nn.softmax(self._slot_logits)\n",
    "            self.slot_ids = tf.argmax(self._slot_logits, -1)\n",
    "\n",
    "            # Slot (any)\n",
    "            state_proj = tf.layers.dense(\n",
    "                tf.concat([self._inputs_encoder_state, self._previous_output_encoder_state], -1),\n",
    "                self._hidden_size,\n",
    "                activation = tf.nn.tanh\n",
    "            )\n",
    "            \n",
    "            self._slot_any_logits = tf.layers.dense(\n",
    "                tf.layers.dropout(state_proj, rate=self._dropout),\n",
    "                self._n_slots * 2\n",
    "            )\n",
    "            self._slot_any_logits = tf.reshape(self._slot_any_logits, [-1, self._n_slots, 2])\n",
    "\n",
    "            self.slot_any_probabilites = tf.nn.softmax(self._slot_any_logits)\n",
    "            self.slot_any = tf.argmax(self._slot_any_logits, -1, output_type=tf.int32)\n",
    "    \n",
    "    def _query_result_encoder(self):\n",
    "        with tf.name_scope('query_result_encoder'):\n",
    "            batch_size, n_slots, n_tokens = tf.unstack(tf.shape(self.query_result_values))\n",
    "    \n",
    "            _, _value_encoder_state = self._text_encoder(\n",
    "                inputs = tf.reshape(self._query_result_values_embedded, [-1, n_tokens, self._word_embeddings_shape[1]]),\n",
    "                inputs_length = tf.reshape(self.query_result_values_length, [-1]),\n",
    "                reuse = True\n",
    "            )\n",
    "        \n",
    "            query_result_slot_value = tf.concat([\n",
    "                self._query_result_slots_embedded,\n",
    "                tf.reshape(_value_encoder_state, [batch_size, n_slots, 2*self._hidden_size])\n",
    "            ], -1)\n",
    "            \n",
    "            _, self._query_result_encoder_state = tf.nn.dynamic_rnn(\n",
    "                self._rnn_cell(activation=tf.nn.tanh, dropout=self._dropout),\n",
    "                inputs = query_result_slot_value,\n",
    "                sequence_length = self.query_result_slots_count,\n",
    "                dtype = tf.float32\n",
    "            )\n",
    "\n",
    "    def _context(self):\n",
    "        with tf.name_scope('context'):\n",
    "            context_inputs = tf.layers.dense(\n",
    "                tf.concat([\n",
    "                    self._inputs_encoder_state,\n",
    "                    self._query_result_encoder_state,\n",
    "                    tf.one_hot(self.query_result_state, self._n_query_states, dtype=tf.float32),\n",
    "                ], -1),\n",
    "                2*self.context_state_size\n",
    "            )\n",
    "\n",
    "            context_cell = rnn.MultiRNNCell([\n",
    "                self._rnn_cell(self.context_state_size, activation=tf.nn.tanh, dropout=self._dropout),\n",
    "                self._rnn_cell(self.context_state_size, activation=tf.nn.tanh, dropout=self._dropout),\n",
    "                self._rnn_cell(self.context_state_size, activation=tf.nn.tanh, dropout=self._dropout)\n",
    "            ])\n",
    "\n",
    "            self._context, self.context_state = context_cell(\n",
    "                context_inputs,\n",
    "                tuple(tf.unstack(self.previous_context_state))\n",
    "            )\n",
    "\n",
    "    def _action_policy(self):\n",
    "        with tf.name_scope('action_policy'):\n",
    "            # Value\n",
    "            value_l1 = tf.layers.dense(\n",
    "                tf.layers.dropout(self._context, rate=self._dropout),\n",
    "                self._hidden_size,\n",
    "                activation = tf.nn.tanh\n",
    "            )\n",
    "            self.value = tf.layers.dense(\n",
    "                tf.layers.dropout(value_l1, rate=self._dropout),\n",
    "                1\n",
    "            )\n",
    "            self.value = tf.squeeze(self.value, -1)\n",
    "\n",
    "            # Action\n",
    "            action_l1 = tf.layers.dense(\n",
    "                tf.layers.dropout(self._context, rate=self._dropout),\n",
    "                self._hidden_size,\n",
    "                activation = tf.nn.tanh\n",
    "            )\n",
    "            self._action_logits = tf.layers.dense(\n",
    "                tf.layers.dropout(action_l1, rate=self._dropout),\n",
    "                self._n_actions\n",
    "            )\n",
    "            self.action_probabilities = tf.nn.softmax(self._action_logits)\n",
    "            self.action_ids = tf.argmax(self._action_logits, -1, output_type=tf.int32)\n",
    "        \n",
    "    def _response_generator(self):\n",
    "        with tf.name_scope('response_generator'):\n",
    "            batch_size, _ = tf.unstack(tf.shape(self.inputs))\n",
    "\n",
    "            logits_projection = Dense(self._word_embeddings_shape[0], name='logits_projection')\n",
    "            decoder_cell, decoder_initial_state = self._decoder_cell()\n",
    "\n",
    "            if self._decoder_helper_initializer is not None:\n",
    "                helper = self._decoder_helper_initializer(self._word_embeddings)\n",
    "            else:\n",
    "                helper = seq2seq.GreedyEmbeddingHelper(\n",
    "                    embedding = self._word_embeddings,\n",
    "                    start_tokens = tf.tile([0], [batch_size]),\n",
    "                    end_token = 1\n",
    "                )\n",
    "\n",
    "            decoder = seq2seq.BasicDecoder(\n",
    "                decoder_cell,\n",
    "                helper = helper,\n",
    "                initial_state = decoder_initial_state,\n",
    "                output_layer = logits_projection \n",
    "            )\n",
    "\n",
    "            decoder_outputs, _, _ = seq2seq.dynamic_decode(\n",
    "                decoder = decoder,\n",
    "                impute_finished = True\n",
    "            )\n",
    "            \n",
    "            self._decoder_logits = decoder_outputs.rnn_output\n",
    "            self.decoder_token_ids = tf.argmax(self._decoder_logits, -1, output_type=tf.int32)\n",
    "            \n",
    "    def _decoder_cell(self):\n",
    "        batch_size, _ = tf.unstack(tf.shape(self._context))\n",
    "\n",
    "        attention = seq2seq.BahdanauAttention(\n",
    "            num_units = 2*self._hidden_size,\n",
    "            memory = self._inputs_encoder_outputs,\n",
    "            memory_sequence_length = self.inputs_length\n",
    "        )\n",
    "        \n",
    "        attentive_cell = seq2seq.AttentionWrapper(\n",
    "            cell = self._rnn_cell(self.context_state_size, activation=tf.nn.tanh),\n",
    "            attention_mechanism = attention,\n",
    "            attention_layer_size = 2*self._hidden_size,\n",
    "            initial_cell_state = self._context\n",
    "        )\n",
    "\n",
    "        cell = rnn.MultiRNNCell([\n",
    "            attentive_cell,\n",
    "            self._rnn_cell(self.context_state_size, activation=tf.nn.tanh),\n",
    "        ])\n",
    "\n",
    "        initial_state = tuple([\n",
    "            attentive_cell.zero_state(batch_size, tf.float32),\n",
    "            self._context\n",
    "        ])\n",
    "\n",
    "        return cell, initial_state\n",
    "    \n",
    "with tf.Graph().as_default():\n",
    "    def _helper(word_embeddings):\n",
    "        targets = tf.placeholder(tf.float32, [None, None, 300])\n",
    "        targets_length = tf.placeholder(tf.int32, [None])\n",
    "            \n",
    "        def _sample(time, outputs, state):\n",
    "            return tf.cast(tf.argmax(outputs, -1), tf.int32)\n",
    "            \n",
    "        def _next_inputs(time, outputs, state, sample_ids):\n",
    "            return(\n",
    "                tf.reduce_all(time >= targets_length),\n",
    "                tf.matmul(tf.nn.softmax(outputs), word_embeddings),\n",
    "                state,\n",
    "            )\n",
    "    \n",
    "        return seq2seq.CustomHelper(\n",
    "            initialize_fn = lambda: (False, targets[:,0,:]),\n",
    "            sample_fn = _sample,\n",
    "            next_inputs_fn = _next_inputs\n",
    "        )\n",
    "        \n",
    "    \n",
    "    \n",
    "    agent = Agent(\n",
    "        [500,300], 5, 3,\n",
    "        decoder_helper_initializer = _helper\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent(hidden_size=300, n_slots=5, n_actions=3)\n"
     ]
    }
   ],
   "source": [
    "class DecoderCritic(object):\n",
    "\n",
    "    CELL_SIZE = 300\n",
    "\n",
    "    def __init__(self, agent):\n",
    "        self._agent = agent\n",
    "\n",
    "        self.targets = tf.placeholder(tf.int32, [None, None])\n",
    "        self.targets_length = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "        with tf.name_scope('decoder_ac_trainer'):\n",
    "            self._embeddings()\n",
    "            self._targets_encoder()\n",
    "            self._values_decoder()\n",
    "\n",
    "    def _embeddings(self):\n",
    "        with tf.name_scope('embeddings'):\n",
    "            self._targets_embedded = tf.nn.embedding_lookup(\n",
    "                self._agent._word_embeddings,\n",
    "                add_pad_eos(self.targets, self.targets_length)\n",
    "            )\n",
    "\n",
    "    def _targets_encoder(self):\n",
    "        with tf.name_scope('targets_encoder'):\n",
    "            (_outputs, _state) = tf.nn.bidirectional_dynamic_rnn(\n",
    "                cell_fw = rnn.GRUCell(self.CELL_SIZE, activation=tf.nn.tanh),\n",
    "                cell_bw = rnn.GRUCell(self.CELL_SIZE, activation=tf.nn.tanh),\n",
    "                inputs = self._targets_embedded,\n",
    "                sequence_length = self.targets_length,\n",
    "                dtype = tf.float32\n",
    "             )\n",
    "\n",
    "            self._targets_encoder_outputs = tf.concat(_outputs, -1)\n",
    "            self._targets_encoder_state = tf.concat(_state, -1)\n",
    "\n",
    "    def _values_decoder(self):\n",
    "        with tf.name_scope('values_decoder'):\n",
    "            decoder_cell, decoder_initial_state = self._decoder_cell()\n",
    "\n",
    "            _outputs, _ = tf.nn.dynamic_rnn(\n",
    "                decoder_cell,\n",
    "                inputs = self._agent._decoder_logits,\n",
    "                sequence_length = self.targets_length,\n",
    "                initial_state = decoder_initial_state,\n",
    "                dtype = tf.float32\n",
    "            )\n",
    "\n",
    "            self.values = tf.layers.dense(_outputs, 1)\n",
    "\n",
    "    def _decoder_cell(self):\n",
    "        batch_size, _ = tf.unstack(tf.shape(self.targets))\n",
    "\n",
    "        attention = seq2seq.BahdanauAttention(\n",
    "            num_units = 2*self.CELL_SIZE,\n",
    "            memory = self._targets_encoder_outputs,\n",
    "            memory_sequence_length = self.targets_length\n",
    "        )\n",
    "        \n",
    "        attentive_cell = seq2seq.AttentionWrapper(\n",
    "            cell = rnn.GRUCell(2*self.CELL_SIZE, activation=tf.nn.tanh),\n",
    "            attention_mechanism = attention,\n",
    "            attention_layer_size = 2*self.CELL_SIZE,\n",
    "            initial_cell_state = self._targets_encoder_state\n",
    "        )\n",
    "\n",
    "        return (\n",
    "            attentive_cell,\n",
    "            attentive_cell.zero_state(batch_size, tf.float32),\n",
    "        )\n",
    "    \n",
    "with tf.Graph().as_default():\n",
    "    agent = Agent(\n",
    "        [500,300], 5, 3\n",
    "    )\n",
    "    \n",
    "    critic = DecoderCritic(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'decoder_ac_trainer/values_decoder/dense/BiasAdd:0' shape=(?, ?, 1) dtype=float32>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4500994164652013"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "references = ['i like dogs more than any other animals i like dogs more .'.split(' ')]\n",
    "candidate = 'I like dogs more than any other animals'.split(' ')\n",
    "\n",
    "sentence_bleu(references, candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'animalsilikedogs': 1,\n",
       "  'anyotheranimalsi': 1,\n",
       "  'dogsmorethanany': 1,\n",
       "  'ilikedogsmore': 2,\n",
       "  'likedogsmore.': 1,\n",
       "  'likedogsmorethan': 1,\n",
       "  'morethananyother': 1,\n",
       "  'otheranimalsilike': 1,\n",
       "  'thananyotheranimals': 1},\n",
       " {'Ilikedogsmore': 1,\n",
       "  'dogsmorethanany': 1,\n",
       "  'likedogsmorethan': 1,\n",
       "  'morethananyother': 1,\n",
       "  'thananyotheranimals': 1})"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bleu(reference, candidate):\n",
    "    def n_grams(tokens, n=4):\n",
    "        for i in range(len(tokens) - 3):\n",
    "            yield ''.join(tokens[i:i+n])\n",
    "            \n",
    "    def n_gram_counts(n_grams):\n",
    "        counts = dict()\n",
    "        for n_gram in n_grams:\n",
    "            if n_gram in counts:\n",
    "                counts[n_gram] += 1\n",
    "                continue\n",
    "            counts[n_gram] = 1\n",
    "        return counts\n",
    "    \n",
    "    reference_counts = n_gram_counts(n_grams(reference))\n",
    "    candidate_counts = n_gram_counts(n_grams(candidate))\n",
    "    \n",
    "    return(reference_counts, candidate_counts) \n",
    "\n",
    "bleu(references[0], candidate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
